{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# klue/beart-base 모델 구성요소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimduhyeon/anaconda3/envs/2024_NLP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"hun3359/klue-bert-base-sentiment\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"\\ubd84\\ub178\",\n",
      "    \"1\": \"\\ud234\\ud234\\ub300\\ub294\",\n",
      "    \"2\": \"\\uc88c\\uc808\\ud55c\",\n",
      "    \"3\": \"\\uc9dc\\uc99d\\ub0b4\\ub294\",\n",
      "    \"4\": \"\\ubc29\\uc5b4\\uc801\\uc778\",\n",
      "    \"5\": \"\\uc545\\uc758\\uc801\\uc778\",\n",
      "    \"6\": \"\\uc548\\ub2ec\\ud558\\ub294\",\n",
      "    \"7\": \"\\uad6c\\uc5ed\\uc9c8 \\ub098\\ub294\",\n",
      "    \"8\": \"\\ub178\\uc5ec\\uc6cc\\ud558\\ub294\",\n",
      "    \"9\": \"\\uc131\\uac00\\uc2e0\",\n",
      "    \"10\": \"\\uc2ac\\ud514\",\n",
      "    \"11\": \"\\uc2e4\\ub9dd\\ud55c\",\n",
      "    \"12\": \"\\ube44\\ud1b5\\ud55c\",\n",
      "    \"13\": \"\\ud6c4\\ud68c\\ub418\\ub294\",\n",
      "    \"14\": \"\\uc6b0\\uc6b8\\ud55c\",\n",
      "    \"15\": \"\\ub9c8\\ube44\\ub41c\",\n",
      "    \"16\": \"\\uc5fc\\uc138\\uc801\\uc778\",\n",
      "    \"17\": \"\\ub208\\ubb3c\\uc774 \\ub098\\ub294\",\n",
      "    \"18\": \"\\ub099\\ub2f4\\ud55c\",\n",
      "    \"19\": \"\\ud658\\uba78\\uc744 \\ub290\\ub07c\\ub294\",\n",
      "    \"20\": \"\\ubd88\\uc548\",\n",
      "    \"21\": \"\\ub450\\ub824\\uc6b4\",\n",
      "    \"22\": \"\\uc2a4\\ud2b8\\ub808\\uc2a4 \\ubc1b\\ub294\",\n",
      "    \"23\": \"\\ucde8\\uc57d\\ud55c\",\n",
      "    \"24\": \"\\ud63c\\ub780\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"25\": \"\\ub2f9\\ud639\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"26\": \"\\ud68c\\uc758\\uc801\\uc778\",\n",
      "    \"27\": \"\\uac71\\uc815\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"28\": \"\\uc870\\uc2ec\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"29\": \"\\ucd08\\uc870\\ud55c\",\n",
      "    \"30\": \"\\uc0c1\\ucc98\",\n",
      "    \"31\": \"\\uc9c8\\ud22c\\ud558\\ub294\",\n",
      "    \"32\": \"\\ubc30\\uc2e0\\ub2f9\\ud55c\",\n",
      "    \"33\": \"\\uace0\\ub9bd\\ub41c\",\n",
      "    \"34\": \"\\ucda9\\uaca9 \\ubc1b\\uc740\",\n",
      "    \"35\": \"\\uac00\\ub09c\\ud55c \\ubd88\\uc6b0\\ud55c\",\n",
      "    \"36\": \"\\ud76c\\uc0dd\\ub41c\",\n",
      "    \"37\": \"\\uc5b5\\uc6b8\\ud55c\",\n",
      "    \"38\": \"\\uad34\\ub85c\\uc6cc\\ud558\\ub294\",\n",
      "    \"39\": \"\\ubc84\\ub824\\uc9c4\",\n",
      "    \"40\": \"\\ub2f9\\ud669\",\n",
      "    \"41\": \"\\uace0\\ub9bd\\ub41c(\\ub2f9\\ud669\\ud55c)\",\n",
      "    \"42\": \"\\ub0a8\\uc758 \\uc2dc\\uc120\\uc744 \\uc758\\uc2dd\\ud558\\ub294\",\n",
      "    \"43\": \"\\uc678\\ub85c\\uc6b4\",\n",
      "    \"44\": \"\\uc5f4\\ub4f1\\uac10\",\n",
      "    \"45\": \"\\uc8c4\\ucc45\\uac10\\uc758\",\n",
      "    \"46\": \"\\ubd80\\ub044\\ub7ec\\uc6b4\",\n",
      "    \"47\": \"\\ud610\\uc624\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"48\": \"\\ud55c\\uc2ec\\ud55c\",\n",
      "    \"49\": \"\\ud63c\\ub780\\uc2a4\\ub7ec\\uc6b4(\\ub2f9\\ud669\\ud55c)\",\n",
      "    \"50\": \"\\uae30\\uc068\",\n",
      "    \"51\": \"\\uac10\\uc0ac\\ud558\\ub294\",\n",
      "    \"52\": \"\\uc2e0\\ub8b0\\ud558\\ub294\",\n",
      "    \"53\": \"\\ud3b8\\uc548\\ud55c\",\n",
      "    \"54\": \"\\ub9cc\\uc871\\uc2a4\\ub7ec\\uc6b4\",\n",
      "    \"55\": \"\\ud765\\ubd84\",\n",
      "    \"56\": \"\\ub290\\uae0b\",\n",
      "    \"57\": \"\\uc548\\ub3c4\",\n",
      "    \"58\": \"\\uc2e0\\uc774 \\ub09c\",\n",
      "    \"59\": \"\\uc790\\uc2e0\\ud558\\ub294\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"\\uac00\\ub09c\\ud55c \\ubd88\\uc6b0\\ud55c\": 35,\n",
      "    \"\\uac10\\uc0ac\\ud558\\ub294\": 51,\n",
      "    \"\\uac71\\uc815\\uc2a4\\ub7ec\\uc6b4\": 27,\n",
      "    \"\\uace0\\ub9bd\\ub41c\": 33,\n",
      "    \"\\uace0\\ub9bd\\ub41c(\\ub2f9\\ud669\\ud55c)\": 41,\n",
      "    \"\\uad34\\ub85c\\uc6cc\\ud558\\ub294\": 38,\n",
      "    \"\\uad6c\\uc5ed\\uc9c8 \\ub098\\ub294\": 7,\n",
      "    \"\\uae30\\uc068\": 50,\n",
      "    \"\\ub099\\ub2f4\\ud55c\": 18,\n",
      "    \"\\ub0a8\\uc758 \\uc2dc\\uc120\\uc744 \\uc758\\uc2dd\\ud558\\ub294\": 42,\n",
      "    \"\\ub178\\uc5ec\\uc6cc\\ud558\\ub294\": 8,\n",
      "    \"\\ub208\\ubb3c\\uc774 \\ub098\\ub294\": 17,\n",
      "    \"\\ub290\\uae0b\": 56,\n",
      "    \"\\ub2f9\\ud639\\uc2a4\\ub7ec\\uc6b4\": 25,\n",
      "    \"\\ub2f9\\ud669\": 40,\n",
      "    \"\\ub450\\ub824\\uc6b4\": 21,\n",
      "    \"\\ub9c8\\ube44\\ub41c\": 15,\n",
      "    \"\\ub9cc\\uc871\\uc2a4\\ub7ec\\uc6b4\": 54,\n",
      "    \"\\ubc29\\uc5b4\\uc801\\uc778\": 4,\n",
      "    \"\\ubc30\\uc2e0\\ub2f9\\ud55c\": 32,\n",
      "    \"\\ubc84\\ub824\\uc9c4\": 39,\n",
      "    \"\\ubd80\\ub044\\ub7ec\\uc6b4\": 46,\n",
      "    \"\\ubd84\\ub178\": 0,\n",
      "    \"\\ubd88\\uc548\": 20,\n",
      "    \"\\ube44\\ud1b5\\ud55c\": 12,\n",
      "    \"\\uc0c1\\ucc98\": 30,\n",
      "    \"\\uc131\\uac00\\uc2e0\": 9,\n",
      "    \"\\uc2a4\\ud2b8\\ub808\\uc2a4 \\ubc1b\\ub294\": 22,\n",
      "    \"\\uc2ac\\ud514\": 10,\n",
      "    \"\\uc2e0\\ub8b0\\ud558\\ub294\": 52,\n",
      "    \"\\uc2e0\\uc774 \\ub09c\": 58,\n",
      "    \"\\uc2e4\\ub9dd\\ud55c\": 11,\n",
      "    \"\\uc545\\uc758\\uc801\\uc778\": 5,\n",
      "    \"\\uc548\\ub2ec\\ud558\\ub294\": 6,\n",
      "    \"\\uc548\\ub3c4\": 57,\n",
      "    \"\\uc5b5\\uc6b8\\ud55c\": 37,\n",
      "    \"\\uc5f4\\ub4f1\\uac10\": 44,\n",
      "    \"\\uc5fc\\uc138\\uc801\\uc778\": 16,\n",
      "    \"\\uc678\\ub85c\\uc6b4\": 43,\n",
      "    \"\\uc6b0\\uc6b8\\ud55c\": 14,\n",
      "    \"\\uc790\\uc2e0\\ud558\\ub294\": 59,\n",
      "    \"\\uc870\\uc2ec\\uc2a4\\ub7ec\\uc6b4\": 28,\n",
      "    \"\\uc88c\\uc808\\ud55c\": 2,\n",
      "    \"\\uc8c4\\ucc45\\uac10\\uc758\": 45,\n",
      "    \"\\uc9c8\\ud22c\\ud558\\ub294\": 31,\n",
      "    \"\\uc9dc\\uc99d\\ub0b4\\ub294\": 3,\n",
      "    \"\\ucd08\\uc870\\ud55c\": 29,\n",
      "    \"\\ucda9\\uaca9 \\ubc1b\\uc740\": 34,\n",
      "    \"\\ucde8\\uc57d\\ud55c\": 23,\n",
      "    \"\\ud234\\ud234\\ub300\\ub294\": 1,\n",
      "    \"\\ud3b8\\uc548\\ud55c\": 53,\n",
      "    \"\\ud55c\\uc2ec\\ud55c\": 48,\n",
      "    \"\\ud610\\uc624\\uc2a4\\ub7ec\\uc6b4\": 47,\n",
      "    \"\\ud63c\\ub780\\uc2a4\\ub7ec\\uc6b4\": 24,\n",
      "    \"\\ud63c\\ub780\\uc2a4\\ub7ec\\uc6b4(\\ub2f9\\ud669\\ud55c)\": 49,\n",
      "    \"\\ud658\\uba78\\uc744 \\ub290\\ub07c\\ub294\": 19,\n",
      "    \"\\ud68c\\uc758\\uc801\\uc778\": 26,\n",
      "    \"\\ud6c4\\ud68c\\ub418\\ub294\": 13,\n",
      "    \"\\ud765\\ubd84\": 55,\n",
      "    \"\\ud76c\\uc0dd\\ub41c\": 36\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "# Load the model configuration\n",
    "model_name = \"hun3359/klue-bert-base-sentiment\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "# Print the model configuration\n",
    "print(config)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '분노', 1: '툴툴대는', 2: '좌절한', 3: '짜증내는', 4: '방어적인', 5: '악의적인', 6: '안달하는', 7: '구역질 나는', 8: '노여워하는', 9: '성가신', 10: '슬픔', 11: '실망한', 12: '비통한', 13: '후회되는', 14: '우울한', 15: '마비된', 16: '염세적인', 17: '눈물이 나는', 18: '낙담한', 19: '환멸을 느끼는', 20: '불안', 21: '두려운', 22: '스트레스 받는', 23: '취약한', 24: '혼란스러운', 25: '당혹스러운', 26: '회의적인', 27: '걱정스러운', 28: '조심스러운', 29: '초조한', 30: '상처', 31: '질투하는', 32: '배신당한', 33: '고립된', 34: '충격 받은', 35: '가난한 불우한', 36: '희생된', 37: '억울한', 38: '괴로워하는', 39: '버려진', 40: '당황', 41: '고립된(당황한)', 42: '남의 시선을 의식하는', 43: '외로운', 44: '열등감', 45: '죄책감의', 46: '부끄러운', 47: '혐오스러운', 48: '한심한', 49: '혼란스러운(당황한)', 50: '기쁨', 51: '감사하는', 52: '신뢰하는', 53: '편안한', 54: '만족스러운', 55: '흥분', 56: '느긋', 57: '안도', 58: '신이 난', 59: '자신하는'}\n",
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=60, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 모델의 구성 정보 확인\n",
    "config = model.config\n",
    "print(config.id2label)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 piepline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimduhyeon/anaconda3/envs/2024_NLP/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': '분노', 'score': 0.0009786674054339528},\n",
       "  {'label': '툴툴대는', 'score': 0.0007189540192484856},\n",
       "  {'label': '좌절한', 'score': 0.0004811719700228423},\n",
       "  {'label': '짜증내는', 'score': 0.0005220891325734556},\n",
       "  {'label': '방어적인', 'score': 0.000584463938139379},\n",
       "  {'label': '악의적인', 'score': 0.0005010592867620289},\n",
       "  {'label': '안달하는', 'score': 0.001795150456018746},\n",
       "  {'label': '구역질 나는', 'score': 0.0005015964270569384},\n",
       "  {'label': '노여워하는', 'score': 0.001159032341092825},\n",
       "  {'label': '성가신', 'score': 0.001238232129253447},\n",
       "  {'label': '슬픔', 'score': 0.0014904619893059134},\n",
       "  {'label': '실망한', 'score': 0.0005433920305222273},\n",
       "  {'label': '비통한', 'score': 0.001839932519942522},\n",
       "  {'label': '후회되는', 'score': 0.0006045732880011201},\n",
       "  {'label': '우울한', 'score': 0.00036713769077323377},\n",
       "  {'label': '마비된', 'score': 0.0007024029619060457},\n",
       "  {'label': '염세적인', 'score': 0.0005359635688364506},\n",
       "  {'label': '눈물이 나는', 'score': 0.005477156024426222},\n",
       "  {'label': '낙담한', 'score': 0.0006621293723583221},\n",
       "  {'label': '환멸을 느끼는', 'score': 0.0004351734241936356},\n",
       "  {'label': '불안', 'score': 0.0031474262941628695},\n",
       "  {'label': '두려운', 'score': 0.003060254268348217},\n",
       "  {'label': '스트레스 받는', 'score': 0.0008414683979935944},\n",
       "  {'label': '취약한', 'score': 0.0029679746367037296},\n",
       "  {'label': '혼란스러운', 'score': 0.0020202146843075752},\n",
       "  {'label': '당혹스러운', 'score': 0.001466113142669201},\n",
       "  {'label': '회의적인', 'score': 0.00047346253995783627},\n",
       "  {'label': '걱정스러운', 'score': 0.001920438720844686},\n",
       "  {'label': '조심스러운', 'score': 0.00306521519087255},\n",
       "  {'label': '초조한', 'score': 0.0014589035417884588},\n",
       "  {'label': '상처', 'score': 0.00046286103315651417},\n",
       "  {'label': '질투하는', 'score': 0.0007635125075466931},\n",
       "  {'label': '배신당한', 'score': 0.0013339637080207467},\n",
       "  {'label': '고립된', 'score': 0.0009008862543851137},\n",
       "  {'label': '충격 받은', 'score': 0.00035887962440028787},\n",
       "  {'label': '가난한 불우한', 'score': 0.0013474219013005495},\n",
       "  {'label': '희생된', 'score': 0.0017015297198668122},\n",
       "  {'label': '억울한', 'score': 0.0007258935365825891},\n",
       "  {'label': '괴로워하는', 'score': 0.00045390307786874473},\n",
       "  {'label': '버려진', 'score': 0.0004771989770233631},\n",
       "  {'label': '당황', 'score': 0.0008099101250991225},\n",
       "  {'label': '고립된(당황한)', 'score': 0.000624852895271033},\n",
       "  {'label': '남의 시선을 의식하는', 'score': 0.0009218316990882158},\n",
       "  {'label': '외로운', 'score': 0.0005325737874954939},\n",
       "  {'label': '열등감', 'score': 0.0002757904294412583},\n",
       "  {'label': '죄책감의', 'score': 0.001740605803206563},\n",
       "  {'label': '부끄러운', 'score': 0.0029355627484619617},\n",
       "  {'label': '혐오스러운', 'score': 0.000982205499894917},\n",
       "  {'label': '한심한', 'score': 0.001125082722865045},\n",
       "  {'label': '혼란스러운(당황한)', 'score': 0.0013940457720309496},\n",
       "  {'label': '기쁨', 'score': 0.10911813378334045},\n",
       "  {'label': '감사하는', 'score': 0.3736228942871094},\n",
       "  {'label': '신뢰하는', 'score': 0.205898255109787},\n",
       "  {'label': '편안한', 'score': 0.047411009669303894},\n",
       "  {'label': '만족스러운', 'score': 0.02740909345448017},\n",
       "  {'label': '흥분', 'score': 0.047505371272563934},\n",
       "  {'label': '느긋', 'score': 0.006507003679871559},\n",
       "  {'label': '안도', 'score': 0.013081456534564495},\n",
       "  {'label': '신이 난', 'score': 0.07740414887666702},\n",
       "  {'label': '자신하는', 'score': 0.030613884329795837}],\n",
       " [{'label': '분노', 'score': 0.13922099769115448},\n",
       "  {'label': '툴툴대는', 'score': 0.043982427567243576},\n",
       "  {'label': '좌절한', 'score': 0.011887560598552227},\n",
       "  {'label': '짜증내는', 'score': 0.030670952051877975},\n",
       "  {'label': '방어적인', 'score': 0.040500737726688385},\n",
       "  {'label': '악의적인', 'score': 0.34600433707237244},\n",
       "  {'label': '안달하는', 'score': 0.010028183460235596},\n",
       "  {'label': '구역질 나는', 'score': 0.029505757614970207},\n",
       "  {'label': '노여워하는', 'score': 0.06422243267297745},\n",
       "  {'label': '성가신', 'score': 0.010086883790791035},\n",
       "  {'label': '슬픔', 'score': 0.002046399051323533},\n",
       "  {'label': '실망한', 'score': 0.003919936716556549},\n",
       "  {'label': '비통한', 'score': 0.0026352033019065857},\n",
       "  {'label': '후회되는', 'score': 0.0018252230947837234},\n",
       "  {'label': '우울한', 'score': 0.0043277316726744175},\n",
       "  {'label': '마비된', 'score': 0.0016333692474290729},\n",
       "  {'label': '염세적인', 'score': 0.006151900626718998},\n",
       "  {'label': '눈물이 나는', 'score': 0.0016510901041328907},\n",
       "  {'label': '낙담한', 'score': 0.0030473233200609684},\n",
       "  {'label': '환멸을 느끼는', 'score': 0.014579376205801964},\n",
       "  {'label': '불안', 'score': 0.0017108374740928411},\n",
       "  {'label': '두려운', 'score': 0.0017712580738589168},\n",
       "  {'label': '스트레스 받는', 'score': 0.004186438862234354},\n",
       "  {'label': '취약한', 'score': 0.0029987760353833437},\n",
       "  {'label': '혼란스러운', 'score': 0.0019036681624129415},\n",
       "  {'label': '당혹스러운', 'score': 0.0010758541757240891},\n",
       "  {'label': '회의적인', 'score': 0.00409081531688571},\n",
       "  {'label': '걱정스러운', 'score': 0.003048887010663748},\n",
       "  {'label': '조심스러운', 'score': 0.0015371444169431925},\n",
       "  {'label': '초조한', 'score': 0.0011540292762219906},\n",
       "  {'label': '상처', 'score': 0.01738947257399559},\n",
       "  {'label': '질투하는', 'score': 0.04073435440659523},\n",
       "  {'label': '배신당한', 'score': 0.07723808288574219},\n",
       "  {'label': '고립된', 'score': 0.005065564531832933},\n",
       "  {'label': '충격 받은', 'score': 0.0037480283062905073},\n",
       "  {'label': '가난한 불우한', 'score': 0.0011015216587111354},\n",
       "  {'label': '희생된', 'score': 0.0016634226776659489},\n",
       "  {'label': '억울한', 'score': 0.0040276143699884415},\n",
       "  {'label': '괴로워하는', 'score': 0.005957569926977158},\n",
       "  {'label': '버려진', 'score': 0.006865156814455986},\n",
       "  {'label': '당황', 'score': 0.0011281620245426893},\n",
       "  {'label': '고립된(당황한)', 'score': 0.00123741221614182},\n",
       "  {'label': '남의 시선을 의식하는', 'score': 0.0012936131097376347},\n",
       "  {'label': '외로운', 'score': 0.0012034381506964564},\n",
       "  {'label': '열등감', 'score': 0.014470336027443409},\n",
       "  {'label': '죄책감의', 'score': 0.001626719837076962},\n",
       "  {'label': '부끄러운', 'score': 0.0007294906536117196},\n",
       "  {'label': '혐오스러운', 'score': 0.009222026914358139},\n",
       "  {'label': '한심한', 'score': 0.002861201064661145},\n",
       "  {'label': '혼란스러운(당황한)', 'score': 0.002454690635204315},\n",
       "  {'label': '기쁨', 'score': 0.000675960211083293},\n",
       "  {'label': '감사하는', 'score': 0.00047694434761069715},\n",
       "  {'label': '신뢰하는', 'score': 0.0007536686025559902},\n",
       "  {'label': '편안한', 'score': 0.000592889089602977},\n",
       "  {'label': '만족스러운', 'score': 0.00039040885167196393},\n",
       "  {'label': '흥분', 'score': 0.001639038324356079},\n",
       "  {'label': '느긋', 'score': 0.0006135863368399441},\n",
       "  {'label': '안도', 'score': 0.0006272921455092728},\n",
       "  {'label': '신이 난', 'score': 0.0005294602597132325},\n",
       "  {'label': '자신하는', 'score': 0.002277300925925374}]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이프라인 생성\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# 예측할 텍스트\n",
    "texts = [\"사랑해\", \"미워해\"]\n",
    "\n",
    "# 레이블 매핑 (주어진 레이블 사용)\n",
    "id2label = {0: '분노', 1: '툴툴대는', 2: '좌절한', 3: '짜증내는', 4: '방어적인', 5: '악의적인', 6: '안달하는', 7: '구역질 나는', 8: '노여워하는', 9: '성가신', 10: '슬픔', 11: '실망한', 12: '비통한', 13: '후회되는', 14: '우울한', 15: '마비된', 16: '염세적인', 17: '눈물이 나는', 18: '낙담한', 19: '환멸을 느끼는', 20: '불안', 21: '두려운', 22: '스트레스 받는', 23: '취약한', 24: '혼란스러운', 25: '당혹스러운', 26: '회의적인', 27: '걱정스러운', 28: '조심스러운', 29: '초조한', 30: '상처', 31: '질투하는', 32: '배신당한', 33: '고립된', 34: '충격 받은', 35: '가난한 불우한', 36: '희생된', 37: '억울한', 38: '괴로워하는', 39: '버려진', 40: '당황', 41: '고립된(당황한)', 42: '남의 시선을 의식하는', 43: '외로운', 44: '열등감', 45: '죄책감의', 46: '부끄러운', 47: '혐오스러운', 48: '한심한', 49: '혼란스러운(당황한)', 50: '기쁨', 51: '감사하는', 52: '신뢰하는', 53: '편안한', 54: '만족스러운', 55: '흥분', 56: '느긋', 57: '안도', 58: '신이 난', 59: '자신하는'}\n",
    "\n",
    "# 예측\n",
    "predictions = pipeline(texts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 사랑해\n",
      "Top 5 Predictions: [('감사하는', 0.3736231029033661), ('신뢰하는', 0.20589770376682281), ('기쁨', 0.10911829769611359), ('신이 난', 0.07740432024002075), ('흥분', 0.04750553518533707)]\n",
      "\n",
      "Text: 미워해\n",
      "Top 5 Predictions: [('악의적인', 0.3460046648979187), ('분노', 0.13922077417373657), ('배신당한', 0.07723791897296906), ('노여워하는', 0.06422232836484909), ('툴툴대는', 0.04398241266608238)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for text, preds in zip(texts, predictions):\n",
    "    sorted_preds = sorted(preds, key=lambda x: x['score'], reverse=True)[:5]\n",
    "    top_5 = [(pred['label'], pred['score']) for i, pred in enumerate(sorted_preds)]\n",
    "    print(f\"Text: {text}\\nTop 5 Predictions: {top_5}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "너 없는 지금도 눈부신 하늘과\n",
      "눈부시게 웃는 사람들\n",
      "나의 헤어짐을 모르는 세상은\n",
      "슬프도록 그대로인데\n",
      "시간마저 데려가지 못하게\n",
      "나만은 널 보내지 못했나봐\n",
      "가시처럼 깊게 박힌 기억은\n",
      "아파도 아픈줄 모르고\n",
      "그대 기억이 지난 사랑이\n",
      "내 안을 파고 드는 가시가 되어\n",
      "제발 가라고 아주 가라고\n",
      "애써도 나를 괴롭히는데\n",
      "아픈만큼 너를 잊게 된다면\n",
      "차라리 앓고 나면 그만인데\n",
      "가시처럼 깊게 박힌 기억은\n",
      "아파도 아픈 줄 모르고\n",
      "제발 가라고 아주 가라고\n",
      "애써도 나를 괴롭히는데\n",
      "너무 사랑했던 나를\n",
      "크게 두려웠던 나를\n",
      "미치도록 너를 그리워했던\n",
      "날 이제는 놓아줘\n",
      "보이지 않아 내 안에 숨어\n",
      "잊으려 하면 할수록 더 아파와\n",
      "제발 가라고 아주 가라고\n",
      "애써도 나를 괴롭히는데\n",
      "\n",
      "Top 1 Prediction: 성가신 (Probability: 0.0986)\n",
      "Top 2 Prediction: 혼란스러운 (Probability: 0.0500)\n",
      "Top 3 Prediction: 두려운 (Probability: 0.0496)\n",
      "Top 4 Prediction: 안달하는 (Probability: 0.0456)\n",
      "Top 5 Prediction: 노여워하는 (Probability: 0.0389)\n",
      "Top 6 Prediction: 분노 (Probability: 0.0388)\n",
      "Top 7 Prediction: 짜증내는 (Probability: 0.0372)\n",
      "Top 8 Prediction: 악의적인 (Probability: 0.0356)\n",
      "Top 9 Prediction: 혼란스러운(당황한) (Probability: 0.0332)\n",
      "Top 10 Prediction: 방어적인 (Probability: 0.0319)\n",
      "\n",
      "Input: 옛날 옛날에 남양주시 와부읍\n",
      "덕소리에서 자란 한 소년이 있었어요\n",
      "아이는 주머니에 아무것도 없었지만\n",
      "어머니의 사랑은 가득해\n",
      "항상 웃음 짓던 소년이였죠\n",
      "어느 날 그 소년 앞에\n",
      "금을 두른 부자가 나타났답니다\n",
      "부자는 그에게 물었어요\n",
      "너에게 미래를 줄 테니\n",
      "지금 이 순간을 나와 바꾸지 않겠니?\n",
      "나 평생 꿈만을 꿨죠\n",
      "알잖아요 꿈은 안 들잖아 돈\n",
      "나 이 순간을 나 평생 떠올렸죠\n",
      "친구들이 대학을 갈 때\n",
      "난 한강에 가서 술을 마셨네\n",
      "되뇌이면서 '세상은 날 싫어해'\n",
      "그렇지 그렇지 그럴만했어\n",
      "그때는 몰라 그리고 애써\n",
      "알려고 하지도 않잖아\n",
      "눈물을 흘렸지 내 방 속에서\n",
      "눈물 흘려 여의도에서\n",
      "두 눈물 맛이 달라 아\n",
      "빌었어\n",
      "빌었어 밤마다\n",
      "이럴 땐 술김에 오그라들게\n",
      "두 손을 모으고 말야\n",
      "Oh oh 빌었어\n",
      "빌었어 밤마다\n",
      "나 무교잖아\n",
      "근데 하늘에다가\n",
      "비는 걸 보면 있나 봐\n",
      "내 소원을 들어줄 어떤 이 (hey)\n",
      "Top 1 Prediction: 성가신 (Probability: 0.0609)\n",
      "Top 2 Prediction: 두려운 (Probability: 0.0553)\n",
      "Top 3 Prediction: 안달하는 (Probability: 0.0465)\n",
      "Top 4 Prediction: 악의적인 (Probability: 0.0423)\n",
      "Top 5 Prediction: 혼란스러운 (Probability: 0.0393)\n",
      "Top 6 Prediction: 노여워하는 (Probability: 0.0389)\n",
      "Top 7 Prediction: 방어적인 (Probability: 0.0383)\n",
      "Top 8 Prediction: 분노 (Probability: 0.0371)\n",
      "Top 9 Prediction: 취약한 (Probability: 0.0310)\n",
      "Top 10 Prediction: 짜증내는 (Probability: 0.0294)\n",
      "\n",
      "Input: \n",
      "니가 없는 거리에는 내가 할 일이 없어서\n",
      "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
      "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
      "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
      "어디쯤에 머무는지 또 어떻게 살아가는지\n",
      "걷다 보면 누가 말해줄 것 같아\n",
      "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
      "그리운 날들 오늘 밤 나를 찾아온다\n",
      "널 그리는 널 부르는 내 하루는\n",
      "애태워도 마주친 추억이 반가워\n",
      "날 부르는 목소리에 돌아보면\n",
      "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
      "막다른 길 다다라서 낯익은 벽 기대 보면\n",
      "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
      "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
      "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
      "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
      "걷다 보면 누가 말해줄 것 같아\n",
      "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
      "그리운 날들 오늘 밤 나를 찾아온다\n",
      "널 그리는 널 부르는 내 하루는\n",
      "애태워도 마주친 추억이 반가워\n",
      "날 부르는 목소리에 돌아보면\n",
      "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
      "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
      "이 거리는 널 기다린다고\n",
      "널 그리는 널 부르는 내 하루는\n",
      "애태워도 마주친 추억이 반가워\n",
      "날 부르는 목소리에 돌아보면\n",
      "텅 빈 거리 어느새 수많은 니 모습만\n",
      "가득해\n",
      "\n",
      "Top 1 Prediction: 두려운 (Probability: 0.0552)\n",
      "Top 2 Prediction: 안달하는 (Probability: 0.0447)\n",
      "Top 3 Prediction: 악의적인 (Probability: 0.0406)\n",
      "Top 4 Prediction: 성가신 (Probability: 0.0386)\n",
      "Top 5 Prediction: 분노 (Probability: 0.0368)\n",
      "Top 6 Prediction: 염세적인 (Probability: 0.0325)\n",
      "Top 7 Prediction: 방어적인 (Probability: 0.0317)\n",
      "Top 8 Prediction: 노여워하는 (Probability: 0.0316)\n",
      "Top 9 Prediction: 혼란스러운 (Probability: 0.0307)\n",
      "Top 10 Prediction: 취약한 (Probability: 0.0263)\n",
      "\n",
      "Input: \n",
      "아침에 눈을 떴을 때 너를\n",
      "길을 걷다 멍하니 너를\n",
      "지금은 내 곁에 없는 너를\n",
      "그리워하네 바보처럼\n",
      "나보다 행복하기를 바래\n",
      "내 생각하지 않기를 바래\n",
      "더 좋은 사람 만나길 바래\n",
      "다시는 내게 올 수 없게\n",
      "안개처럼 사라져 간 다시 못 올 그 지난날\n",
      "함께한 추억 모두 흘려보낼게\n",
      "널 잊어야 해 힘들어도\n",
      "널 지워야 해 기억 속에서\n",
      "네가 떠난 후에 난 죽을 것같이 아파도\n",
      "두 번 다시 울지 않을게\n",
      "잊을게 잊을게\n",
      "아직도 휴대폰에 네 이름\n",
      "지우지도 못하고 있어\n",
      "전화기 들고 한참을 서서\n",
      "널 생각하네 바보처럼\n",
      "안개처럼 사라져 간 다시 못 올 그 지난날\n",
      "함께한 추억 모두 흘려보낼게\n",
      "널 잊어야 해 힘들어도\n",
      "널 지워야 해 기억 속에서\n",
      "네가 떠난 후에 난 죽을 것같이 아파도\n",
      "다시는 너를 찾지 않아\n",
      "아침에 눈을 떴을 때 너를 아직도\n",
      "길을 걷다 멍하니 너를\n",
      "지금은 내 곁에 없는 너를\n",
      "그리워하네 바보처럼\n",
      "\n",
      "\n",
      "Top 1 Prediction: 성가신 (Probability: 0.0679)\n",
      "Top 2 Prediction: 두려운 (Probability: 0.0573)\n",
      "Top 3 Prediction: 안달하는 (Probability: 0.0504)\n",
      "Top 4 Prediction: 혼란스러운 (Probability: 0.0435)\n",
      "Top 5 Prediction: 악의적인 (Probability: 0.0374)\n",
      "Top 6 Prediction: 방어적인 (Probability: 0.0374)\n",
      "Top 7 Prediction: 혼란스러운(당황한) (Probability: 0.0326)\n",
      "Top 8 Prediction: 노여워하는 (Probability: 0.0322)\n",
      "Top 9 Prediction: 죄책감의 (Probability: 0.0289)\n",
      "Top 10 Prediction: 후회되는 (Probability: 0.0288)\n",
      "\n",
      "Input: \n",
      "너와 나 둘이 정신없이 가는 곳\n",
      "정처 없이 가는 곳, 정해지지 않은 곳\n",
      "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
      "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
      "Excuse me 잠시만 아직까진 우린 남\n",
      "하지만 조만간 중독성을 자랑하는 장난감\n",
      "지금 이 느낌적인 느낌이 통하는 느낌\n",
      "녹아버릴 아이스크림\n",
      "지금이 우리에게는 꿈이야\n",
      "너와 나 둘이서 추는 춤이야\n",
      "기분은 미친 듯이 예술이야\n",
      "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
      "하늘을 날아가는 기분이야\n",
      "죽어도 상관없는 지금이야\n",
      "심장은 터질 듯이 예술이야\n",
      "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
      "예술이야 (예술이야), 예술이야 (예술이야)\n",
      "예술이야 (예술이야), 이런 날이 올 줄이야\n",
      "예술이야 (예술이야), 예술이야 (예술이야)\n",
      "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
      "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
      "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
      "눈이 점점 풀린다\n",
      "니도 따라 풀린다\n",
      "끌린다, 너에 대한 수수께끼가 풀린다\n",
      "지금 이 춤에 너의 가빠진 숨에\n",
      "수줍음에 you know what I mean\n",
      "지금이 우리에게는 꿈이야\n",
      "너와 나 둘이서 추는 춤이야\n",
      "기분은 미친 듯이 예술이야\n",
      "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
      "하늘을 날아가는 기분이야\n",
      "죽어도 상관없는 지금이야\n",
      "Top 1 Prediction: 흥분 (Probability: 0.2290)\n",
      "Top 2 Prediction: 신이 난 (Probability: 0.1311)\n",
      "Top 3 Prediction: 기쁨 (Probability: 0.0748)\n",
      "Top 4 Prediction: 안달하는 (Probability: 0.0545)\n",
      "Top 5 Prediction: 자신하는 (Probability: 0.0420)\n",
      "Top 6 Prediction: 느긋 (Probability: 0.0342)\n",
      "Top 7 Prediction: 만족스러운 (Probability: 0.0312)\n",
      "Top 8 Prediction: 마비된 (Probability: 0.0303)\n",
      "Top 9 Prediction: 눈물이 나는 (Probability: 0.0295)\n",
      "Top 10 Prediction: 염세적인 (Probability: 0.0269)\n",
      "\n",
      "Input: \n",
      "파란 하늘 위로 훨훨 날아가겠죠\n",
      "어려서 꿈꾸었던 비행기 타고\n",
      "기다리는 동안 아무 말도 못 해요\n",
      "내 생각 말할 순 없어요\n",
      "모든 준비 다 끝났어 곱게 차려 입고 나선\n",
      "바깥 풍경마저 들뜬 기분 때가 왔어\n",
      "하늘 위로 날으는 순간이야 조금은 두려워도\n",
      "애써 내색할 순 없어 이번이 처음이지만\n",
      "전에 자주 비행했었잖아 친구들과 말썽장이\n",
      "거북이 비행기로 올라탈 준비됐나\n",
      "수많은 사람들 속을 지나쳐 마지막 게이트야\n",
      "나도 모르게 안절부절 하고 있어\n",
      "이럴 땐 침착해 좀 자연스럽게\n",
      "파란 하늘 위로 훨훨 날아가겠죠\n",
      "어려서 꿈꾸었던 비행기 타고\n",
      "기다리는 동안 아무 말도 못 해요\n",
      "내 생각 말할 순 없어요 yes remember\n",
      "Yes fly 다들 아무 일도 없는 듯\n",
      "하늘을 나르는데 아무 걱정 없는 듯\n",
      "왠지 철딱서니 없었나 문득\n",
      "이런 내 모습 촌스러워 입 다문 듯\n",
      "쳐다보지 말아요\n",
      "다들 처음 탈 때 이러지 않았나요\n",
      "딴 데 봐요 신경 쓰지 마요\n",
      "나 혼자 이런 게 나 좋아요\n",
      "어떤 느낌일까 정말 새들처럼 나는 기분\n",
      "세상 모든 것이 점처럼 보여지겠지 개구쟁이\n",
      "거북이 비행기로 드디어 출발한다\n",
      "수많은 사람들 속을 지나쳐 마지막 게이트야\n",
      "나도 모르게 안절부절하고 있어\n",
      "이럴 땐 침착해 좀 자연스럽게\n",
      "파란 하늘 위로 훨훨 날아가겠죠\n",
      "어려서 꿈꾸었던 비행기 타고\n",
      "기다리는 동안 아무 말도 못 해요\n",
      "내 생각 말할 순 없어요\n",
      "기다리는 동안 아무 말도 못 해요\n",
      "내 생각 말할 순 없어요 yes remember\n",
      "\n",
      "Top 1 Prediction: 안달하는 (Probability: 0.0927)\n",
      "Top 2 Prediction: 짜증내는 (Probability: 0.0414)\n",
      "Top 3 Prediction: 분노 (Probability: 0.0411)\n",
      "Top 4 Prediction: 성가신 (Probability: 0.0397)\n",
      "Top 5 Prediction: 두려운 (Probability: 0.0368)\n",
      "Top 6 Prediction: 초조한 (Probability: 0.0353)\n",
      "Top 7 Prediction: 혼란스러운 (Probability: 0.0332)\n",
      "Top 8 Prediction: 노여워하는 (Probability: 0.0318)\n",
      "Top 9 Prediction: 희생된 (Probability: 0.0278)\n",
      "Top 10 Prediction: 염세적인 (Probability: 0.0274)\n",
      "\n",
      "Input: \n",
      "마음 울적한 날엔 거리를 걸어보고\n",
      "향기로운 칵테일에 취해도보고\n",
      "한편의 시가 있는 전시회장도 가고\n",
      "밤새도록 그리움에 편질 쓰고파\n",
      "모차르트 피아노 협주곡 이십일번\n",
      "그 음악을 내 귓가에 속삭여주며\n",
      "아침 햇살 눈부심에 나를 깨워줄\n",
      "그런 연인이 내게 있으면\n",
      "나는 아직 순수함을 느끼고 싶어\n",
      "어느 작은 우체국 앞 계단에 앉아\n",
      "프리지아 꽃 향기를 내게 안겨줄\n",
      "그런 연인을 만나 봤으면\n",
      "마음 울적한 날엔 거리를 걸어보고\n",
      "향기로운 칵테일에 취해도보고\n",
      "한편의 시가 있는 전시회장도 가고\n",
      "밤새도록 그리움에 편질 쓰고파\n",
      "모차르트 피아노 협주곡 이십일번\n",
      "그 음악을 내 귓가에 속삭여 주며\n",
      "아침 햇살 눈부심에 나를 깨워줄\n",
      "그런 연인이 내게 있으면\n",
      "나는 아직 순수함을 느끼고 싶어\n",
      "어느 작은 우체국 앞 계단에 앉아\n",
      "프리지아 꽃향기를 내게 안겨줄\n",
      "그런 연인을 만나 봤으면\n",
      "마음 울적한 날엔 거리를 걸어보고\n",
      "향기로운 칵테일에 취해도보고\n",
      "한편의 시가 있는 전시회장도 가고\n",
      "밤새도록 그리움에 편질 쓰고파\n",
      "창밖에는 우울한 비가 내리고 있어\n",
      "내 마음도 그 비따라 우울해지네\n",
      "누가 내게 눈부신 사랑을 가져 줄까\n",
      "이 세상은 나로 인해 아름다운데\n",
      "마음 울적한 날엔 거리를 걸어보고\n",
      "향기로운 칵테일에 취해도보고\n",
      "한편의 시가 있는 전시회장도 가고\n",
      "밤새도록 그리움에 편질 쓰고파\n",
      "\n",
      "Top 1 Prediction: 악의적인 (Probability: 0.0599)\n",
      "Top 2 Prediction: 두려운 (Probability: 0.0486)\n",
      "Top 3 Prediction: 안달하는 (Probability: 0.0483)\n",
      "Top 4 Prediction: 성가신 (Probability: 0.0401)\n",
      "Top 5 Prediction: 분노 (Probability: 0.0325)\n",
      "Top 6 Prediction: 노여워하는 (Probability: 0.0289)\n",
      "Top 7 Prediction: 취약한 (Probability: 0.0268)\n",
      "Top 8 Prediction: 방어적인 (Probability: 0.0267)\n",
      "Top 9 Prediction: 염세적인 (Probability: 0.0262)\n",
      "Top 10 Prediction: 희생된 (Probability: 0.0262)\n",
      "\n",
      "Input: \n",
      "알잖아 너를 이토록\n",
      "사랑하며 기다린 나를\n",
      "뭐가 그리 바쁜지\n",
      "너무 보기 힘들어\n",
      "너 도대체 뭐하고 다니니\n",
      "그게 아냐 이유는 묻지마\n",
      "그냥 믿고 기다려 주겠니\n",
      "내게도 사랑을 위한\n",
      "시간이 필요해\n",
      "널 받아들일 수 있게\n",
      "일부로 피하는 거니 노\n",
      "삐삐쳐도 아무 소식 없는 너\n",
      "싫으면 그냥 싫다고\n",
      "솔직하게 말해봐\n",
      "말리지마 내 이런 사랑을\n",
      "너만 보면 미칠 것 같은 이맘을\n",
      "누가 알겠어 웨딩드레스 입은\n",
      "니 곁에 다른 사람이\n",
      "난 두려워\n",
      "나보다 더 멋진\n",
      "그런 남자 니가 만날까봐\n",
      "아니야 그렇지 않아\n",
      "정말 너 하나뿐야\n",
      "속는 셈치고 한번 믿어봐\n",
      "내 눈에는 너무 이쁜 그녀를\n",
      "자랑스레 친구에게 보여줬지\n",
      "그 친구 네게 미안하다며\n",
      "그녀 얘길 싸 그리다 했지\n",
      "그녈 만난 많은 남자 중에\n",
      "내 친구만도 여러명이야\n",
      "말도 안돼 믿을 수 없어\n",
      "혹시 쌍둥이\n",
      "우연히 너를 보았지\n",
      "다른 남자품안에 너를\n",
      "한번도 볼 수 없었던\n",
      "너무 행복한 미소\n",
      "내 사랑은 무너져 버렸어\n",
      "그게 아냐 변명이 아니라\n",
      "그 남자는 나완 상관없어\n",
      "잠시 나 어지러웠어\n",
      "기댄 것 뿐이야\n",
      "날 오해하지 말아 줘\n",
      "나 역시 많은 여자들\n",
      "만났다가 헤어져도 봤지만\n",
      "한꺼번에 많은 여자를\n",
      "만난 적은 없었어\n",
      "니가 뭔데 날 아프게 하니\n",
      "너 때문에 상처돼 버린 내 사랑\n",
      "이제 다시는 너의 어떤 만남도\n",
      "나같은 사랑 없을걸\n",
      "난 두려워 나 역시 다시는\n",
      "이런 사랑 할수 없을까봐\n",
      "믿을 수 없겠지만은\n",
      "니가 첫사랑인데\n",
      "떠나버리면 어떡하라구\n",
      "사랑까지는 바라지도 않을께\n",
      "네 곁에 항상 있게만 해줘\n",
      "제발 제발\n",
      "\n",
      "Top 1 Prediction: 악의적인 (Probability: 0.0743)\n",
      "Top 2 Prediction: 안달하는 (Probability: 0.0526)\n",
      "Top 3 Prediction: 분노 (Probability: 0.0525)\n",
      "Top 4 Prediction: 짜증내는 (Probability: 0.0494)\n",
      "Top 5 Prediction: 노여워하는 (Probability: 0.0427)\n",
      "Top 6 Prediction: 희생된 (Probability: 0.0400)\n",
      "Top 7 Prediction: 염세적인 (Probability: 0.0398)\n",
      "Top 8 Prediction: 성가신 (Probability: 0.0327)\n",
      "Top 9 Prediction: 구역질 나는 (Probability: 0.0315)\n",
      "Top 10 Prediction: 방어적인 (Probability: 0.0282)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 입력 텍스트 정의\n",
    "input_texts = [\"\"\"\n",
    "너 없는 지금도 눈부신 하늘과\n",
    "눈부시게 웃는 사람들\n",
    "나의 헤어짐을 모르는 세상은\n",
    "슬프도록 그대로인데\n",
    "시간마저 데려가지 못하게\n",
    "나만은 널 보내지 못했나봐\n",
    "가시처럼 깊게 박힌 기억은\n",
    "아파도 아픈줄 모르고\n",
    "그대 기억이 지난 사랑이\n",
    "내 안을 파고 드는 가시가 되어\n",
    "제발 가라고 아주 가라고\n",
    "애써도 나를 괴롭히는데\n",
    "아픈만큼 너를 잊게 된다면\n",
    "차라리 앓고 나면 그만인데\n",
    "가시처럼 깊게 박힌 기억은\n",
    "아파도 아픈 줄 모르고\n",
    "제발 가라고 아주 가라고\n",
    "애써도 나를 괴롭히는데\n",
    "너무 사랑했던 나를\n",
    "크게 두려웠던 나를\n",
    "미치도록 너를 그리워했던\n",
    "날 이제는 놓아줘\n",
    "보이지 않아 내 안에 숨어\n",
    "잊으려 하면 할수록 더 아파와\n",
    "제발 가라고 아주 가라고\n",
    "애써도 나를 괴롭히는데\n",
    "\"\"\", \"\"\"옛날 옛날에 남양주시 와부읍\n",
    "덕소리에서 자란 한 소년이 있었어요\n",
    "아이는 주머니에 아무것도 없었지만\n",
    "어머니의 사랑은 가득해\n",
    "항상 웃음 짓던 소년이였죠\n",
    "어느 날 그 소년 앞에\n",
    "금을 두른 부자가 나타났답니다\n",
    "부자는 그에게 물었어요\n",
    "너에게 미래를 줄 테니\n",
    "지금 이 순간을 나와 바꾸지 않겠니?\n",
    "나 평생 꿈만을 꿨죠\n",
    "알잖아요 꿈은 안 들잖아 돈\n",
    "나 이 순간을 나 평생 떠올렸죠\n",
    "친구들이 대학을 갈 때\n",
    "난 한강에 가서 술을 마셨네\n",
    "되뇌이면서 '세상은 날 싫어해'\n",
    "그렇지 그렇지 그럴만했어\n",
    "그때는 몰라 그리고 애써\n",
    "알려고 하지도 않잖아\n",
    "눈물을 흘렸지 내 방 속에서\n",
    "눈물 흘려 여의도에서\n",
    "두 눈물 맛이 달라 아\n",
    "빌었어\n",
    "빌었어 밤마다\n",
    "이럴 땐 술김에 오그라들게\n",
    "두 손을 모으고 말야\n",
    "Oh oh 빌었어\n",
    "빌었어 밤마다\n",
    "나 무교잖아\n",
    "근데 하늘에다가\n",
    "비는 걸 보면 있나 봐\n",
    "내 소원을 들어줄 어떤 이 (hey)\"\"\",\"\"\"\n",
    "니가 없는 거리에는 내가 할 일이 없어서\n",
    "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
    "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
    "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
    "어디쯤에 머무는지 또 어떻게 살아가는지\n",
    "걷다 보면 누가 말해줄 것 같아\n",
    "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
    "그리운 날들 오늘 밤 나를 찾아온다\n",
    "널 그리는 널 부르는 내 하루는\n",
    "애태워도 마주친 추억이 반가워\n",
    "날 부르는 목소리에 돌아보면\n",
    "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
    "막다른 길 다다라서 낯익은 벽 기대 보면\n",
    "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
    "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
    "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
    "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
    "걷다 보면 누가 말해줄 것 같아\n",
    "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
    "그리운 날들 오늘 밤 나를 찾아온다\n",
    "널 그리는 널 부르는 내 하루는\n",
    "애태워도 마주친 추억이 반가워\n",
    "날 부르는 목소리에 돌아보면\n",
    "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
    "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
    "이 거리는 널 기다린다고\n",
    "널 그리는 널 부르는 내 하루는\n",
    "애태워도 마주친 추억이 반가워\n",
    "날 부르는 목소리에 돌아보면\n",
    "텅 빈 거리 어느새 수많은 니 모습만\n",
    "가득해\n",
    "\"\"\", \"\"\"\n",
    "아침에 눈을 떴을 때 너를\n",
    "길을 걷다 멍하니 너를\n",
    "지금은 내 곁에 없는 너를\n",
    "그리워하네 바보처럼\n",
    "나보다 행복하기를 바래\n",
    "내 생각하지 않기를 바래\n",
    "더 좋은 사람 만나길 바래\n",
    "다시는 내게 올 수 없게\n",
    "안개처럼 사라져 간 다시 못 올 그 지난날\n",
    "함께한 추억 모두 흘려보낼게\n",
    "널 잊어야 해 힘들어도\n",
    "널 지워야 해 기억 속에서\n",
    "네가 떠난 후에 난 죽을 것같이 아파도\n",
    "두 번 다시 울지 않을게\n",
    "잊을게 잊을게\n",
    "아직도 휴대폰에 네 이름\n",
    "지우지도 못하고 있어\n",
    "전화기 들고 한참을 서서\n",
    "널 생각하네 바보처럼\n",
    "안개처럼 사라져 간 다시 못 올 그 지난날\n",
    "함께한 추억 모두 흘려보낼게\n",
    "널 잊어야 해 힘들어도\n",
    "널 지워야 해 기억 속에서\n",
    "네가 떠난 후에 난 죽을 것같이 아파도\n",
    "다시는 너를 찾지 않아\n",
    "아침에 눈을 떴을 때 너를 아직도\n",
    "길을 걷다 멍하니 너를\n",
    "지금은 내 곁에 없는 너를\n",
    "그리워하네 바보처럼\n",
    "\n",
    "\"\"\", \"\"\"\n",
    "너와 나 둘이 정신없이 가는 곳\n",
    "정처 없이 가는 곳, 정해지지 않은 곳\n",
    "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
    "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
    "Excuse me 잠시만 아직까진 우린 남\n",
    "하지만 조만간 중독성을 자랑하는 장난감\n",
    "지금 이 느낌적인 느낌이 통하는 느낌\n",
    "녹아버릴 아이스크림\n",
    "지금이 우리에게는 꿈이야\n",
    "너와 나 둘이서 추는 춤이야\n",
    "기분은 미친 듯이 예술이야\n",
    "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
    "하늘을 날아가는 기분이야\n",
    "죽어도 상관없는 지금이야\n",
    "심장은 터질 듯이 예술이야\n",
    "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
    "예술이야 (예술이야), 예술이야 (예술이야)\n",
    "예술이야 (예술이야), 이런 날이 올 줄이야\n",
    "예술이야 (예술이야), 예술이야 (예술이야)\n",
    "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
    "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
    "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
    "눈이 점점 풀린다\n",
    "니도 따라 풀린다\n",
    "끌린다, 너에 대한 수수께끼가 풀린다\n",
    "지금 이 춤에 너의 가빠진 숨에\n",
    "수줍음에 you know what I mean\n",
    "지금이 우리에게는 꿈이야\n",
    "너와 나 둘이서 추는 춤이야\n",
    "기분은 미친 듯이 예술이야\n",
    "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
    "하늘을 날아가는 기분이야\n",
    "죽어도 상관없는 지금이야\"\"\",\"\"\"\n",
    "파란 하늘 위로 훨훨 날아가겠죠\n",
    "어려서 꿈꾸었던 비행기 타고\n",
    "기다리는 동안 아무 말도 못 해요\n",
    "내 생각 말할 순 없어요\n",
    "모든 준비 다 끝났어 곱게 차려 입고 나선\n",
    "바깥 풍경마저 들뜬 기분 때가 왔어\n",
    "하늘 위로 날으는 순간이야 조금은 두려워도\n",
    "애써 내색할 순 없어 이번이 처음이지만\n",
    "전에 자주 비행했었잖아 친구들과 말썽장이\n",
    "거북이 비행기로 올라탈 준비됐나\n",
    "수많은 사람들 속을 지나쳐 마지막 게이트야\n",
    "나도 모르게 안절부절 하고 있어\n",
    "이럴 땐 침착해 좀 자연스럽게\n",
    "파란 하늘 위로 훨훨 날아가겠죠\n",
    "어려서 꿈꾸었던 비행기 타고\n",
    "기다리는 동안 아무 말도 못 해요\n",
    "내 생각 말할 순 없어요 yes remember\n",
    "Yes fly 다들 아무 일도 없는 듯\n",
    "하늘을 나르는데 아무 걱정 없는 듯\n",
    "왠지 철딱서니 없었나 문득\n",
    "이런 내 모습 촌스러워 입 다문 듯\n",
    "쳐다보지 말아요\n",
    "다들 처음 탈 때 이러지 않았나요\n",
    "딴 데 봐요 신경 쓰지 마요\n",
    "나 혼자 이런 게 나 좋아요\n",
    "어떤 느낌일까 정말 새들처럼 나는 기분\n",
    "세상 모든 것이 점처럼 보여지겠지 개구쟁이\n",
    "거북이 비행기로 드디어 출발한다\n",
    "수많은 사람들 속을 지나쳐 마지막 게이트야\n",
    "나도 모르게 안절부절하고 있어\n",
    "이럴 땐 침착해 좀 자연스럽게\n",
    "파란 하늘 위로 훨훨 날아가겠죠\n",
    "어려서 꿈꾸었던 비행기 타고\n",
    "기다리는 동안 아무 말도 못 해요\n",
    "내 생각 말할 순 없어요\n",
    "기다리는 동안 아무 말도 못 해요\n",
    "내 생각 말할 순 없어요 yes remember\n",
    "\"\"\",\"\"\"\n",
    "마음 울적한 날엔 거리를 걸어보고\n",
    "향기로운 칵테일에 취해도보고\n",
    "한편의 시가 있는 전시회장도 가고\n",
    "밤새도록 그리움에 편질 쓰고파\n",
    "모차르트 피아노 협주곡 이십일번\n",
    "그 음악을 내 귓가에 속삭여주며\n",
    "아침 햇살 눈부심에 나를 깨워줄\n",
    "그런 연인이 내게 있으면\n",
    "나는 아직 순수함을 느끼고 싶어\n",
    "어느 작은 우체국 앞 계단에 앉아\n",
    "프리지아 꽃 향기를 내게 안겨줄\n",
    "그런 연인을 만나 봤으면\n",
    "마음 울적한 날엔 거리를 걸어보고\n",
    "향기로운 칵테일에 취해도보고\n",
    "한편의 시가 있는 전시회장도 가고\n",
    "밤새도록 그리움에 편질 쓰고파\n",
    "모차르트 피아노 협주곡 이십일번\n",
    "그 음악을 내 귓가에 속삭여 주며\n",
    "아침 햇살 눈부심에 나를 깨워줄\n",
    "그런 연인이 내게 있으면\n",
    "나는 아직 순수함을 느끼고 싶어\n",
    "어느 작은 우체국 앞 계단에 앉아\n",
    "프리지아 꽃향기를 내게 안겨줄\n",
    "그런 연인을 만나 봤으면\n",
    "마음 울적한 날엔 거리를 걸어보고\n",
    "향기로운 칵테일에 취해도보고\n",
    "한편의 시가 있는 전시회장도 가고\n",
    "밤새도록 그리움에 편질 쓰고파\n",
    "창밖에는 우울한 비가 내리고 있어\n",
    "내 마음도 그 비따라 우울해지네\n",
    "누가 내게 눈부신 사랑을 가져 줄까\n",
    "이 세상은 나로 인해 아름다운데\n",
    "마음 울적한 날엔 거리를 걸어보고\n",
    "향기로운 칵테일에 취해도보고\n",
    "한편의 시가 있는 전시회장도 가고\n",
    "밤새도록 그리움에 편질 쓰고파\n",
    "\"\"\",\"\"\"\n",
    "알잖아 너를 이토록\n",
    "사랑하며 기다린 나를\n",
    "뭐가 그리 바쁜지\n",
    "너무 보기 힘들어\n",
    "너 도대체 뭐하고 다니니\n",
    "그게 아냐 이유는 묻지마\n",
    "그냥 믿고 기다려 주겠니\n",
    "내게도 사랑을 위한\n",
    "시간이 필요해\n",
    "널 받아들일 수 있게\n",
    "일부로 피하는 거니 노\n",
    "삐삐쳐도 아무 소식 없는 너\n",
    "싫으면 그냥 싫다고\n",
    "솔직하게 말해봐\n",
    "말리지마 내 이런 사랑을\n",
    "너만 보면 미칠 것 같은 이맘을\n",
    "누가 알겠어 웨딩드레스 입은\n",
    "니 곁에 다른 사람이\n",
    "난 두려워\n",
    "나보다 더 멋진\n",
    "그런 남자 니가 만날까봐\n",
    "아니야 그렇지 않아\n",
    "정말 너 하나뿐야\n",
    "속는 셈치고 한번 믿어봐\n",
    "내 눈에는 너무 이쁜 그녀를\n",
    "자랑스레 친구에게 보여줬지\n",
    "그 친구 네게 미안하다며\n",
    "그녀 얘길 싸 그리다 했지\n",
    "그녈 만난 많은 남자 중에\n",
    "내 친구만도 여러명이야\n",
    "말도 안돼 믿을 수 없어\n",
    "혹시 쌍둥이\n",
    "우연히 너를 보았지\n",
    "다른 남자품안에 너를\n",
    "한번도 볼 수 없었던\n",
    "너무 행복한 미소\n",
    "내 사랑은 무너져 버렸어\n",
    "그게 아냐 변명이 아니라\n",
    "그 남자는 나완 상관없어\n",
    "잠시 나 어지러웠어\n",
    "기댄 것 뿐이야\n",
    "날 오해하지 말아 줘\n",
    "나 역시 많은 여자들\n",
    "만났다가 헤어져도 봤지만\n",
    "한꺼번에 많은 여자를\n",
    "만난 적은 없었어\n",
    "니가 뭔데 날 아프게 하니\n",
    "너 때문에 상처돼 버린 내 사랑\n",
    "이제 다시는 너의 어떤 만남도\n",
    "나같은 사랑 없을걸\n",
    "난 두려워 나 역시 다시는\n",
    "이런 사랑 할수 없을까봐\n",
    "믿을 수 없겠지만은\n",
    "니가 첫사랑인데\n",
    "떠나버리면 어떡하라구\n",
    "사랑까지는 바라지도 않을께\n",
    "네 곁에 항상 있게만 해줘\n",
    "제발 제발\n",
    "\"\"\"]\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "# 입력 텍스트를 토큰화\n",
    "inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 예측 수행\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=inputs['input_ids'])\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "# 결과 출력 및 시각화\n",
    "for i, text in enumerate(input_texts):\n",
    "    print(f\"Input: {text}\")\n",
    "    # print(f\"Prediction: {id2label[predictions[i].item()]} (Probability: {probabilities[i][predictions[i]].item():.4f})\")\n",
    "\n",
    "    top_probabilities, top_indices = torch.topk(probabilities[i], 10)\n",
    "    for j in range(10):\n",
    "        print(f\"Top {j+1} Prediction: {id2label[top_indices[j].item()]} (Probability: {top_probabilities[j].item():.4f})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 여러 label을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# 데이터셋 준비\n",
    "dataset = Dataset.from_pandas(df[['text', 'label_id']])\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "# 데이터셋 토크나이징\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=len(label_mapping))\n",
    "\n",
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# 트레이너 설정\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets,\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "# 예측\n",
    "predictions = trainer.predict(tokenized_datasets)\n",
    "\n",
    "# 예측 결과 확인\n",
    "pred_labels = torch.argmax(predictions.predictions, axis=1)\n",
    "for i, text in enumerate(df['text']):\n",
    "    label = label_mapping[pred_labels[i].item()]\n",
    "    print(f\"Text: {text}\\nPredicted label: {label}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024_NLP",
   "language": "python",
   "name": "2024_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
