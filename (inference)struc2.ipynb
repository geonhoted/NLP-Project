{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6REO4rJjr-q",
        "outputId": "f863ec44-e48d-451e-f22f-d7995be99b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: transformers 4.41.1\n",
            "Uninstalling transformers-4.41.1:\n",
            "  Successfully uninstalled transformers-4.41.1\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, accelerate\n",
            "Successfully installed accelerate-0.30.1 datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 transformers-4.41.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall transformers -y\n",
        "!pip install transformers[torch] datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtrCop5rhPds",
        "outputId": "ae4ea624-8b22-4747-fdd8-72b8aba07b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: google mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vuxAJzZlHo1E"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "# Define model\n",
        "class BertCNNClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, num_labels):\n",
        "        super(BertCNNClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.cnn1 = nn.Conv1d(1536, 512, kernel_size=2, padding=1)\n",
        "        self.cnn2 = nn.Conv1d(512, 64, kernel_size=2, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Linear(64, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        all_hidden_states = torch.stack(outputs.hidden_states)\n",
        "        concatenate_pooling = torch.cat((all_hidden_states[-1], all_hidden_states[-4]), dim=-1)\n",
        "        concatenate_pooling = concatenate_pooling.permute(0, 2, 1)\n",
        "\n",
        "        x = self.relu(self.cnn1(concatenate_pooling))\n",
        "        x = self.relu(self.cnn2(x))\n",
        "        x = self.global_avg_pool(x).squeeze(-1)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udemdLC_AAGD",
        "outputId": "e588e5f3-be23-4264-b4cd-a675f4bffc15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertCNNClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cnn1): Conv1d(1536, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
              "  (cnn2): Conv1d(512, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
              "  (relu): ReLU()\n",
              "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "  (classifier): Linear(in_features=64, out_features=60, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from safetensors.torch import load_file as safe_load_file\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# BERT 모델 로드 및 커스텀 모델 초기화\n",
        "klue_bert = AutoModel.from_pretrained('klue/bert-base', output_hidden_states=True)\n",
        "model = BertCNNClassifier(bert_model=klue_bert, num_labels=60)\n",
        "model.to(device)\n",
        "\n",
        "# checkpoint-18800에서 모델 가중치 로드 (safetensors 사용)\n",
        "checkpoint_path = \"checkpoint-18800/model.safetensors\"\n",
        "state_dict = safe_load_file(checkpoint_path)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Af0ReTbiFddi"
      },
      "outputs": [],
      "source": [
        "id2label = {\n",
        "    0: \"분노\",\n",
        "    1: \"툴툴대는\",\n",
        "    2: \"좌절한\",\n",
        "    3: \"짜증내는\",\n",
        "    4: \"방어적인\",\n",
        "    5: \"악의적인\",\n",
        "    6: \"안달하는\",\n",
        "    7: \"구역질 나는\",\n",
        "    8: \"노여워하는\",\n",
        "    9: \"성가신\",\n",
        "    10: \"슬픔\",\n",
        "    11: \"실망한\",\n",
        "    12: \"비통한\",\n",
        "    13: \"후회되는\",\n",
        "    14: \"우울한\",\n",
        "    15: \"마비된\",\n",
        "    16: \"염세적인\",\n",
        "    17: \"눈물이 나는\",\n",
        "    18: \"낙담한\",\n",
        "    19: \"환멸을 느끼는\",\n",
        "    20: \"불안\",\n",
        "    21: \"두려운\",\n",
        "    22: \"스트레스 받는\",\n",
        "    23: \"취약한\",\n",
        "    24: \"혼란스러운\",\n",
        "    25: \"당혹스러운\",\n",
        "    26: \"회의적인\",\n",
        "    27: \"걱정스러운\",\n",
        "    28: \"조심스러운\",\n",
        "    29: \"초조한\",\n",
        "    30: \"상처\",\n",
        "    31: \"질투하는\",\n",
        "    32: \"배신당한\",\n",
        "    33: \"고립된\",\n",
        "    34: \"충격 받은\",\n",
        "    35: \"가난한, 불우한\",\n",
        "    36: \"희생된\",\n",
        "    37: \"억울한\",\n",
        "    38: \"괴로워하는\",\n",
        "    39: \"버려진\",\n",
        "    40: \"당황\",\n",
        "    41: \"고립된(당황한)\",\n",
        "    42: \"남의 시선을 의식하는\",\n",
        "    43: \"외로운\",\n",
        "    44: \"열등감\",\n",
        "    45: \"죄책감\",\n",
        "    46: \"부끄러운\",\n",
        "    47: \"혐오스러운\",\n",
        "    48: \"한심한\",\n",
        "    49: \"혼란스러운(당황한)\",\n",
        "    50: \"기쁨\",\n",
        "    51: \"감사하는\",\n",
        "    52: \"신뢰하는\",\n",
        "    53: \"편안한\",\n",
        "    54: \"만족스러운\",\n",
        "    55: \"흥분\",\n",
        "    56: \"느긋\",\n",
        "    57: \"안도\",\n",
        "    58: \"신이 난\",\n",
        "    59: \"자신하는\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7q93pYxEhg4",
        "outputId": "bc109565-a6f4-4e7e-c24f-5fb246bdb382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: \n",
            "너 없는 지금도 눈부신 하늘과\n",
            "눈부시게 웃는 사람들\n",
            "나의 헤어짐을 모르는 세상은\n",
            "슬프도록 그대로인데\n",
            "시간마저 데려가지 못하게\n",
            "나만은 널 보내지 못했나봐\n",
            "가시처럼 깊게 박힌 기억은\n",
            "아파도 아픈줄 모르고\n",
            "그대 기억이 지난 사랑이\n",
            "내 안을 파고 드는 가시가 되어\n",
            "제발 가라고 아주 가라고\n",
            "애써도 나를 괴롭히는데\n",
            "아픈만큼 너를 잊게 된다면\n",
            "차라리 앓고 나면 그만인데\n",
            "가시처럼 깊게 박힌 기억은\n",
            "아파도 아픈 줄 모르고\n",
            "제발 가라고 아주 가라고\n",
            "애써도 나를 괴롭히는데\n",
            "너무 사랑했던 나를\n",
            "크게 두려웠던 나를\n",
            "미치도록 너를 그리워했던\n",
            "날 이제는 놓아줘\n",
            "보이지 않아 내 안에 숨어\n",
            "잊으려 하면 할수록 더 아파와\n",
            "제발 가라고 아주 가라고\n",
            "애써도 나를 괴롭히는데\n",
            "\n",
            "Top 1 Prediction: 후회되는 (Probability: 0.0767)\n",
            "Top 2 Prediction: 괴로워하는 (Probability: 0.0726)\n",
            "Top 3 Prediction: 슬픔 (Probability: 0.0664)\n",
            "Top 4 Prediction: 좌절한 (Probability: 0.0534)\n",
            "Top 5 Prediction: 눈물이 나는 (Probability: 0.0531)\n",
            "Top 6 Prediction: 비통한 (Probability: 0.0484)\n",
            "Top 7 Prediction: 외로운 (Probability: 0.0464)\n",
            "Top 8 Prediction: 우울한 (Probability: 0.0459)\n",
            "Top 9 Prediction: 염세적인 (Probability: 0.0372)\n",
            "Top 10 Prediction: 낙담한 (Probability: 0.0245)\n",
            "\n",
            "Input: 옛날 옛날에 남양주시 와부읍\n",
            "덕소리에서 자란 한 소년이 있었어요\n",
            "아이는 주머니에 아무것도 없었지만\n",
            "어머니의 사랑은 가득해\n",
            "항상 웃음 짓던 소년이였죠\n",
            "어느 날 그 소년 앞에\n",
            "금을 두른 부자가 나타났답니다\n",
            "부자는 그에게 물었어요\n",
            "너에게 미래를 줄 테니\n",
            "지금 이 순간을 나와 바꾸지 않겠니?\n",
            "나 평생 꿈만을 꿨죠\n",
            "알잖아요 꿈은 안 들잖아 돈\n",
            "나 이 순간을 나 평생 떠올렸죠\n",
            "친구들이 대학을 갈 때\n",
            "난 한강에 가서 술을 마셨네\n",
            "되뇌이면서 '세상은 날 싫어해'\n",
            "그렇지 그렇지 그럴만했어\n",
            "그때는 몰라 그리고 애써\n",
            "알려고 하지도 않잖아\n",
            "눈물을 흘렸지 내 방 속에서\n",
            "눈물 흘려 여의도에서\n",
            "두 눈물 맛이 달라 아\n",
            "빌었어\n",
            "빌었어 밤마다\n",
            "이럴 땐 술김에 오그라들게\n",
            "두 손을 모으고 말야\n",
            "Oh oh 빌었어\n",
            "빌었어 밤마다\n",
            "나 무교잖아\n",
            "근데 하늘에다가\n",
            "비는 걸 보면 있나 봐\n",
            "내 소원을 들어줄 어떤 이 (hey)\n",
            "Top 1 Prediction: 눈물이 나는 (Probability: 0.1534)\n",
            "Top 2 Prediction: 우울한 (Probability: 0.0620)\n",
            "Top 3 Prediction: 비통한 (Probability: 0.0604)\n",
            "Top 4 Prediction: 슬픔 (Probability: 0.0550)\n",
            "Top 5 Prediction: 가난한, 불우한 (Probability: 0.0518)\n",
            "Top 6 Prediction: 염세적인 (Probability: 0.0389)\n",
            "Top 7 Prediction: 회의적인 (Probability: 0.0318)\n",
            "Top 8 Prediction: 후회되는 (Probability: 0.0282)\n",
            "Top 9 Prediction: 고립된 (Probability: 0.0277)\n",
            "Top 10 Prediction: 마비된 (Probability: 0.0259)\n",
            "\n",
            "Input: \n",
            "니가 없는 거리에는 내가 할 일이 없어서\n",
            "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
            "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
            "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
            "어디쯤에 머무는지 또 어떻게 살아가는지\n",
            "걷다 보면 누가 말해줄 것 같아\n",
            "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
            "그리운 날들 오늘 밤 나를 찾아온다\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
            "막다른 길 다다라서 낯익은 벽 기대 보면\n",
            "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
            "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
            "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
            "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
            "걷다 보면 누가 말해줄 것 같아\n",
            "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
            "그리운 날들 오늘 밤 나를 찾아온다\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
            "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
            "이 거리는 널 기다린다고\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만\n",
            "가득해\n",
            "\n",
            "Top 1 Prediction: 눈물이 나는 (Probability: 0.0960)\n",
            "Top 2 Prediction: 슬픔 (Probability: 0.0801)\n",
            "Top 3 Prediction: 우울한 (Probability: 0.0723)\n",
            "Top 4 Prediction: 마비된 (Probability: 0.0601)\n",
            "Top 5 Prediction: 비통한 (Probability: 0.0360)\n",
            "Top 6 Prediction: 염세적인 (Probability: 0.0343)\n",
            "Top 7 Prediction: 낙담한 (Probability: 0.0338)\n",
            "Top 8 Prediction: 좌절한 (Probability: 0.0320)\n",
            "Top 9 Prediction: 후회되는 (Probability: 0.0288)\n",
            "Top 10 Prediction: 실망한 (Probability: 0.0262)\n",
            "\n",
            "Input: \n",
            "아침에 눈을 떴을 때 너를\n",
            "길을 걷다 멍하니 너를\n",
            "지금은 내 곁에 없는 너를\n",
            "그리워하네 바보처럼\n",
            "나보다 행복하기를 바래\n",
            "내 생각하지 않기를 바래\n",
            "더 좋은 사람 만나길 바래\n",
            "다시는 내게 올 수 없게\n",
            "안개처럼 사라져 간 다시 못 올 그 지난날\n",
            "함께한 추억 모두 흘려보낼게\n",
            "널 잊어야 해 힘들어도\n",
            "널 지워야 해 기억 속에서\n",
            "네가 떠난 후에 난 죽을 것같이 아파도\n",
            "두 번 다시 울지 않을게\n",
            "잊을게 잊을게\n",
            "아직도 휴대폰에 네 이름\n",
            "지우지도 못하고 있어\n",
            "전화기 들고 한참을 서서\n",
            "널 생각하네 바보처럼\n",
            "안개처럼 사라져 간 다시 못 올 그 지난날\n",
            "함께한 추억 모두 흘려보낼게\n",
            "널 잊어야 해 힘들어도\n",
            "널 지워야 해 기억 속에서\n",
            "네가 떠난 후에 난 죽을 것같이 아파도\n",
            "다시는 너를 찾지 않아\n",
            "아침에 눈을 떴을 때 너를 아직도\n",
            "길을 걷다 멍하니 너를\n",
            "지금은 내 곁에 없는 너를\n",
            "그리워하네 바보처럼\n",
            "\n",
            "\n",
            "Top 1 Prediction: 우울한 (Probability: 0.0759)\n",
            "Top 2 Prediction: 좌절한 (Probability: 0.0725)\n",
            "Top 3 Prediction: 괴로워하는 (Probability: 0.0424)\n",
            "Top 4 Prediction: 마비된 (Probability: 0.0416)\n",
            "Top 5 Prediction: 슬픔 (Probability: 0.0408)\n",
            "Top 6 Prediction: 눈물이 나는 (Probability: 0.0389)\n",
            "Top 7 Prediction: 낙담한 (Probability: 0.0346)\n",
            "Top 8 Prediction: 비통한 (Probability: 0.0345)\n",
            "Top 9 Prediction: 염세적인 (Probability: 0.0326)\n",
            "Top 10 Prediction: 회의적인 (Probability: 0.0308)\n",
            "\n",
            "Input: \n",
            "너와 나 둘이 정신없이 가는 곳\n",
            "정처 없이 가는 곳, 정해지지 않은 곳\n",
            "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
            "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
            "Excuse me 잠시만 아직까진 우린 남\n",
            "하지만 조만간 중독성을 자랑하는 장난감\n",
            "지금 이 느낌적인 느낌이 통하는 느낌\n",
            "녹아버릴 아이스크림\n",
            "지금이 우리에게는 꿈이야\n",
            "너와 나 둘이서 추는 춤이야\n",
            "기분은 미친 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "하늘을 날아가는 기분이야\n",
            "죽어도 상관없는 지금이야\n",
            "심장은 터질 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "예술이야 (예술이야), 예술이야 (예술이야)\n",
            "예술이야 (예술이야), 이런 날이 올 줄이야\n",
            "예술이야 (예술이야), 예술이야 (예술이야)\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
            "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
            "눈이 점점 풀린다\n",
            "니도 따라 풀린다\n",
            "끌린다, 너에 대한 수수께끼가 풀린다\n",
            "지금 이 춤에 너의 가빠진 숨에\n",
            "수줍음에 you know what I mean\n",
            "지금이 우리에게는 꿈이야\n",
            "너와 나 둘이서 추는 춤이야\n",
            "기분은 미친 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "하늘을 날아가는 기분이야\n",
            "죽어도 상관없는 지금이야\n",
            "Top 1 Prediction: 신이 난 (Probability: 0.0365)\n",
            "Top 2 Prediction: 질투하는 (Probability: 0.0364)\n",
            "Top 3 Prediction: 구역질 나는 (Probability: 0.0359)\n",
            "Top 4 Prediction: 흥분 (Probability: 0.0347)\n",
            "Top 5 Prediction: 혐오스러운 (Probability: 0.0300)\n",
            "Top 6 Prediction: 부끄러운 (Probability: 0.0293)\n",
            "Top 7 Prediction: 노여워하는 (Probability: 0.0285)\n",
            "Top 8 Prediction: 눈물이 나는 (Probability: 0.0284)\n",
            "Top 9 Prediction: 우울한 (Probability: 0.0281)\n",
            "Top 10 Prediction: 스트레스 받는 (Probability: 0.0263)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 입력 텍스트 정의\n",
        "input_texts = [\"\"\"\n",
        "너 없는 지금도 눈부신 하늘과\n",
        "눈부시게 웃는 사람들\n",
        "나의 헤어짐을 모르는 세상은\n",
        "슬프도록 그대로인데\n",
        "시간마저 데려가지 못하게\n",
        "나만은 널 보내지 못했나봐\n",
        "가시처럼 깊게 박힌 기억은\n",
        "아파도 아픈줄 모르고\n",
        "그대 기억이 지난 사랑이\n",
        "내 안을 파고 드는 가시가 되어\n",
        "제발 가라고 아주 가라고\n",
        "애써도 나를 괴롭히는데\n",
        "아픈만큼 너를 잊게 된다면\n",
        "차라리 앓고 나면 그만인데\n",
        "가시처럼 깊게 박힌 기억은\n",
        "아파도 아픈 줄 모르고\n",
        "제발 가라고 아주 가라고\n",
        "애써도 나를 괴롭히는데\n",
        "너무 사랑했던 나를\n",
        "크게 두려웠던 나를\n",
        "미치도록 너를 그리워했던\n",
        "날 이제는 놓아줘\n",
        "보이지 않아 내 안에 숨어\n",
        "잊으려 하면 할수록 더 아파와\n",
        "제발 가라고 아주 가라고\n",
        "애써도 나를 괴롭히는데\n",
        "\"\"\", \"\"\"옛날 옛날에 남양주시 와부읍\n",
        "덕소리에서 자란 한 소년이 있었어요\n",
        "아이는 주머니에 아무것도 없었지만\n",
        "어머니의 사랑은 가득해\n",
        "항상 웃음 짓던 소년이였죠\n",
        "어느 날 그 소년 앞에\n",
        "금을 두른 부자가 나타났답니다\n",
        "부자는 그에게 물었어요\n",
        "너에게 미래를 줄 테니\n",
        "지금 이 순간을 나와 바꾸지 않겠니?\n",
        "나 평생 꿈만을 꿨죠\n",
        "알잖아요 꿈은 안 들잖아 돈\n",
        "나 이 순간을 나 평생 떠올렸죠\n",
        "친구들이 대학을 갈 때\n",
        "난 한강에 가서 술을 마셨네\n",
        "되뇌이면서 '세상은 날 싫어해'\n",
        "그렇지 그렇지 그럴만했어\n",
        "그때는 몰라 그리고 애써\n",
        "알려고 하지도 않잖아\n",
        "눈물을 흘렸지 내 방 속에서\n",
        "눈물 흘려 여의도에서\n",
        "두 눈물 맛이 달라 아\n",
        "빌었어\n",
        "빌었어 밤마다\n",
        "이럴 땐 술김에 오그라들게\n",
        "두 손을 모으고 말야\n",
        "Oh oh 빌었어\n",
        "빌었어 밤마다\n",
        "나 무교잖아\n",
        "근데 하늘에다가\n",
        "비는 걸 보면 있나 봐\n",
        "내 소원을 들어줄 어떤 이 (hey)\"\"\",\"\"\"\n",
        "니가 없는 거리에는 내가 할 일이 없어서\n",
        "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
        "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
        "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
        "어디쯤에 머무는지 또 어떻게 살아가는지\n",
        "걷다 보면 누가 말해줄 것 같아\n",
        "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
        "그리운 날들 오늘 밤 나를 찾아온다\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
        "막다른 길 다다라서 낯익은 벽 기대 보면\n",
        "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
        "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
        "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
        "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
        "걷다 보면 누가 말해줄 것 같아\n",
        "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
        "그리운 날들 오늘 밤 나를 찾아온다\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
        "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
        "이 거리는 널 기다린다고\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만\n",
        "가득해\n",
        "\"\"\", \"\"\"\n",
        "아침에 눈을 떴을 때 너를\n",
        "길을 걷다 멍하니 너를\n",
        "지금은 내 곁에 없는 너를\n",
        "그리워하네 바보처럼\n",
        "나보다 행복하기를 바래\n",
        "내 생각하지 않기를 바래\n",
        "더 좋은 사람 만나길 바래\n",
        "다시는 내게 올 수 없게\n",
        "안개처럼 사라져 간 다시 못 올 그 지난날\n",
        "함께한 추억 모두 흘려보낼게\n",
        "널 잊어야 해 힘들어도\n",
        "널 지워야 해 기억 속에서\n",
        "네가 떠난 후에 난 죽을 것같이 아파도\n",
        "두 번 다시 울지 않을게\n",
        "잊을게 잊을게\n",
        "아직도 휴대폰에 네 이름\n",
        "지우지도 못하고 있어\n",
        "전화기 들고 한참을 서서\n",
        "널 생각하네 바보처럼\n",
        "안개처럼 사라져 간 다시 못 올 그 지난날\n",
        "함께한 추억 모두 흘려보낼게\n",
        "널 잊어야 해 힘들어도\n",
        "널 지워야 해 기억 속에서\n",
        "네가 떠난 후에 난 죽을 것같이 아파도\n",
        "다시는 너를 찾지 않아\n",
        "아침에 눈을 떴을 때 너를 아직도\n",
        "길을 걷다 멍하니 너를\n",
        "지금은 내 곁에 없는 너를\n",
        "그리워하네 바보처럼\n",
        "\n",
        "\"\"\", \"\"\"\n",
        "너와 나 둘이 정신없이 가는 곳\n",
        "정처 없이 가는 곳, 정해지지 않은 곳\n",
        "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
        "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
        "Excuse me 잠시만 아직까진 우린 남\n",
        "하지만 조만간 중독성을 자랑하는 장난감\n",
        "지금 이 느낌적인 느낌이 통하는 느낌\n",
        "녹아버릴 아이스크림\n",
        "지금이 우리에게는 꿈이야\n",
        "너와 나 둘이서 추는 춤이야\n",
        "기분은 미친 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "하늘을 날아가는 기분이야\n",
        "죽어도 상관없는 지금이야\n",
        "심장은 터질 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "예술이야 (예술이야), 예술이야 (예술이야)\n",
        "예술이야 (예술이야), 이런 날이 올 줄이야\n",
        "예술이야 (예술이야), 예술이야 (예술이야)\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
        "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
        "눈이 점점 풀린다\n",
        "니도 따라 풀린다\n",
        "끌린다, 너에 대한 수수께끼가 풀린다\n",
        "지금 이 춤에 너의 가빠진 숨에\n",
        "수줍음에 you know what I mean\n",
        "지금이 우리에게는 꿈이야\n",
        "너와 나 둘이서 추는 춤이야\n",
        "기분은 미친 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "하늘을 날아가는 기분이야\n",
        "죽어도 상관없는 지금이야\"\"\"]\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "# 입력 텍스트를 토큰화\n",
        "inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "model.to(device)\n",
        "\n",
        "# 예측 수행\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    logits = outputs.logits\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "# 결과 출력 및 시각화\n",
        "for i, text in enumerate(input_texts):\n",
        "    print(f\"Input: {text}\")\n",
        "    # print(f\"Prediction: {id2label[predictions[i].item()]} (Probability: {probabilities[i][predictions[i]].item():.4f})\")\n",
        "\n",
        "    top_probabilities, top_indices = torch.topk(probabilities[i], 10)\n",
        "    for j in range(10):\n",
        "        print(f\"Top {j+1} Prediction: {id2label[top_indices[j].item()]} (Probability: {top_probabilities[j].item():.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: \n",
            "알잖아 너를 이토록\n",
            "사랑하며 기다린 나를\n",
            "뭐가 그리 바쁜지\n",
            "너무 보기 힘들어\n",
            "너 도대체 뭐하고 다니니\n",
            "그게 아냐 이유는 묻지마\n",
            "그냥 믿고 기다려 주겠니\n",
            "내게도 사랑을 위한\n",
            "시간이 필요해\n",
            "널 받아들일 수 있게\n",
            "일부로 피하는 거니 노\n",
            "삐삐쳐도 아무 소식 없는 너\n",
            "싫으면 그냥 싫다고\n",
            "솔직하게 말해봐\n",
            "말리지마 내 이런 사랑을\n",
            "너만 보면 미칠 것 같은 이맘을\n",
            "누가 알겠어 웨딩드레스 입은\n",
            "니 곁에 다른 사람이\n",
            "난 두려워\n",
            "나보다 더 멋진\n",
            "그런 남자 니가 만날까봐\n",
            "아니야 그렇지 않아\n",
            "정말 너 하나뿐야\n",
            "속는 셈치고 한번 믿어봐\n",
            "내 눈에는 너무 이쁜 그녀를\n",
            "자랑스레 친구에게 보여줬지\n",
            "그 친구 네게 미안하다며\n",
            "그녀 얘길 싸 그리다 했지\n",
            "그녈 만난 많은 남자 중에\n",
            "내 친구만도 여러명이야\n",
            "말도 안돼 믿을 수 없어\n",
            "혹시 쌍둥이\n",
            "우연히 너를 보았지\n",
            "다른 남자품안에 너를\n",
            "한번도 볼 수 없었던\n",
            "너무 행복한 미소\n",
            "내 사랑은 무너져 버렸어\n",
            "그게 아냐 변명이 아니라\n",
            "그 남자는 나완 상관없어\n",
            "잠시 나 어지러웠어\n",
            "기댄 것 뿐이야\n",
            "날 오해하지 말아 줘\n",
            "나 역시 많은 여자들\n",
            "만났다가 헤어져도 봤지만\n",
            "한꺼번에 많은 여자를\n",
            "만난 적은 없었어\n",
            "니가 뭔데 날 아프게 하니\n",
            "너 때문에 상처돼 버린 내 사랑\n",
            "이제 다시는 너의 어떤 만남도\n",
            "나같은 사랑 없을걸\n",
            "난 두려워 나 역시 다시는\n",
            "이런 사랑 할수 없을까봐\n",
            "믿을 수 없겠지만은\n",
            "니가 첫사랑인데\n",
            "떠나버리면 어떡하라구\n",
            "사랑까지는 바라지도 않을께\n",
            "네 곁에 항상 있게만 해줘\n",
            "제발 제발\n",
            "\n",
            "Top 1 Prediction: 후회되는 (Probability: 0.0767)\n",
            "Top 2 Prediction: 괴로워하는 (Probability: 0.0726)\n",
            "Top 3 Prediction: 슬픔 (Probability: 0.0664)\n",
            "Top 4 Prediction: 좌절한 (Probability: 0.0534)\n",
            "Top 5 Prediction: 눈물이 나는 (Probability: 0.0531)\n",
            "Top 6 Prediction: 비통한 (Probability: 0.0484)\n",
            "Top 7 Prediction: 외로운 (Probability: 0.0464)\n",
            "Top 8 Prediction: 우울한 (Probability: 0.0459)\n",
            "Top 9 Prediction: 염세적인 (Probability: 0.0372)\n",
            "Top 10 Prediction: 낙담한 (Probability: 0.0245)\n",
            "\n",
            "Input: \n",
            "마음 울적한 날엔 거리를 걸어보고\n",
            "향기로운 칵테일에 취해도보고\n",
            "한편의 시가 있는 전시회장도 가고\n",
            "밤새도록 그리움에 편질 쓰고파\n",
            "모차르트 피아노 협주곡 이십일번\n",
            "그 음악을 내 귓가에 속삭여주며\n",
            "아침 햇살 눈부심에 나를 깨워줄\n",
            "그런 연인이 내게 있으면\n",
            "나는 아직 순수함을 느끼고 싶어\n",
            "어느 작은 우체국 앞 계단에 앉아\n",
            "프리지아 꽃 향기를 내게 안겨줄\n",
            "그런 연인을 만나 봤으면\n",
            "마음 울적한 날엔 거리를 걸어보고\n",
            "향기로운 칵테일에 취해도보고\n",
            "한편의 시가 있는 전시회장도 가고\n",
            "밤새도록 그리움에 편질 쓰고파\n",
            "모차르트 피아노 협주곡 이십일번\n",
            "그 음악을 내 귓가에 속삭여 주며\n",
            "아침 햇살 눈부심에 나를 깨워줄\n",
            "그런 연인이 내게 있으면\n",
            "나는 아직 순수함을 느끼고 싶어\n",
            "어느 작은 우체국 앞 계단에 앉아\n",
            "프리지아 꽃향기를 내게 안겨줄\n",
            "그런 연인을 만나 봤으면\n",
            "마음 울적한 날엔 거리를 걸어보고\n",
            "향기로운 칵테일에 취해도보고\n",
            "한편의 시가 있는 전시회장도 가고\n",
            "밤새도록 그리움에 편질 쓰고파\n",
            "창밖에는 우울한 비가 내리고 있어\n",
            "내 마음도 그 비따라 우울해지네\n",
            "누가 내게 눈부신 사랑을 가져 줄까\n",
            "이 세상은 나로 인해 아름다운데\n",
            "마음 울적한 날엔 거리를 걸어보고\n",
            "향기로운 칵테일에 취해도보고\n",
            "한편의 시가 있는 전시회장도 가고\n",
            "밤새도록 그리움에 편질 쓰고파\n",
            "\n",
            "Top 1 Prediction: 눈물이 나는 (Probability: 0.1534)\n",
            "Top 2 Prediction: 우울한 (Probability: 0.0620)\n",
            "Top 3 Prediction: 비통한 (Probability: 0.0604)\n",
            "Top 4 Prediction: 슬픔 (Probability: 0.0550)\n",
            "Top 5 Prediction: 가난한, 불우한 (Probability: 0.0518)\n",
            "Top 6 Prediction: 염세적인 (Probability: 0.0389)\n",
            "Top 7 Prediction: 회의적인 (Probability: 0.0318)\n",
            "Top 8 Prediction: 후회되는 (Probability: 0.0282)\n",
            "Top 9 Prediction: 고립된 (Probability: 0.0277)\n",
            "Top 10 Prediction: 마비된 (Probability: 0.0259)\n",
            "\n",
            "Input: \n",
            "니가 없는 거리에는 내가 할 일이 없어서\n",
            "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
            "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
            "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
            "어디쯤에 머무는지 또 어떻게 살아가는지\n",
            "걷다 보면 누가 말해줄 것 같아\n",
            "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
            "그리운 날들 오늘 밤 나를 찾아온다\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
            "막다른 길 다다라서 낯익은 벽 기대 보면\n",
            "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
            "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
            "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
            "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
            "걷다 보면 누가 말해줄 것 같아\n",
            "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
            "그리운 날들 오늘 밤 나를 찾아온다\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
            "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
            "이 거리는 널 기다린다고\n",
            "널 그리는 널 부르는 내 하루는\n",
            "애태워도 마주친 추억이 반가워\n",
            "날 부르는 목소리에 돌아보면\n",
            "텅 빈 거리 어느새 수많은 니 모습만\n",
            "가득해\n",
            "\n",
            "Top 1 Prediction: 눈물이 나는 (Probability: 0.0960)\n",
            "Top 2 Prediction: 슬픔 (Probability: 0.0801)\n",
            "Top 3 Prediction: 우울한 (Probability: 0.0723)\n",
            "Top 4 Prediction: 마비된 (Probability: 0.0601)\n",
            "Top 5 Prediction: 비통한 (Probability: 0.0360)\n",
            "Top 6 Prediction: 염세적인 (Probability: 0.0343)\n",
            "Top 7 Prediction: 낙담한 (Probability: 0.0338)\n",
            "Top 8 Prediction: 좌절한 (Probability: 0.0320)\n",
            "Top 9 Prediction: 후회되는 (Probability: 0.0288)\n",
            "Top 10 Prediction: 실망한 (Probability: 0.0262)\n",
            "\n",
            "Input: \n",
            "너와 나 둘이 정신없이 가는 곳\n",
            "정처 없이 가는 곳, 정해지지 않은 곳\n",
            "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
            "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
            "Excuse me 잠시만 아직까진 우린 남\n",
            "하지만 조만간 중독성을 자랑하는 장난감\n",
            "지금 이 느낌적인 느낌이 통하는 느낌\n",
            "녹아버릴 아이스크림\n",
            "지금이 우리에게는 꿈이야\n",
            "너와 나 둘이서 추는 춤이야\n",
            "기분은 미친 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "하늘을 날아가는 기분이야\n",
            "죽어도 상관없는 지금이야\n",
            "심장은 터질 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "예술이야 (예술이야), 예술이야 (예술이야)\n",
            "예술이야 (예술이야), 이런 날이 올 줄이야\n",
            "예술이야 (예술이야), 예술이야 (예술이야)\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
            "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
            "눈이 점점 풀린다\n",
            "니도 따라 풀린다\n",
            "끌린다, 너에 대한 수수께끼가 풀린다\n",
            "지금 이 춤에 너의 가빠진 숨에\n",
            "수줍음에 you know what I mean\n",
            "지금이 우리에게는 꿈이야\n",
            "너와 나 둘이서 추는 춤이야\n",
            "기분은 미친 듯이 예술이야\n",
            "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
            "하늘을 날아가는 기분이야\n",
            "죽어도 상관없는 지금이야\n",
            "Top 1 Prediction: 우울한 (Probability: 0.0759)\n",
            "Top 2 Prediction: 좌절한 (Probability: 0.0725)\n",
            "Top 3 Prediction: 괴로워하는 (Probability: 0.0424)\n",
            "Top 4 Prediction: 마비된 (Probability: 0.0416)\n",
            "Top 5 Prediction: 슬픔 (Probability: 0.0408)\n",
            "Top 6 Prediction: 눈물이 나는 (Probability: 0.0389)\n",
            "Top 7 Prediction: 낙담한 (Probability: 0.0346)\n",
            "Top 8 Prediction: 비통한 (Probability: 0.0345)\n",
            "Top 9 Prediction: 염세적인 (Probability: 0.0326)\n",
            "Top 10 Prediction: 회의적인 (Probability: 0.0308)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 입력 텍스트 정의\n",
        "input_texts = [\"\"\"\n",
        "알잖아 너를 이토록\n",
        "사랑하며 기다린 나를\n",
        "뭐가 그리 바쁜지\n",
        "너무 보기 힘들어\n",
        "너 도대체 뭐하고 다니니\n",
        "그게 아냐 이유는 묻지마\n",
        "그냥 믿고 기다려 주겠니\n",
        "내게도 사랑을 위한\n",
        "시간이 필요해\n",
        "널 받아들일 수 있게\n",
        "일부로 피하는 거니 노\n",
        "삐삐쳐도 아무 소식 없는 너\n",
        "싫으면 그냥 싫다고\n",
        "솔직하게 말해봐\n",
        "말리지마 내 이런 사랑을\n",
        "너만 보면 미칠 것 같은 이맘을\n",
        "누가 알겠어 웨딩드레스 입은\n",
        "니 곁에 다른 사람이\n",
        "난 두려워\n",
        "나보다 더 멋진\n",
        "그런 남자 니가 만날까봐\n",
        "아니야 그렇지 않아\n",
        "정말 너 하나뿐야\n",
        "속는 셈치고 한번 믿어봐\n",
        "내 눈에는 너무 이쁜 그녀를\n",
        "자랑스레 친구에게 보여줬지\n",
        "그 친구 네게 미안하다며\n",
        "그녀 얘길 싸 그리다 했지\n",
        "그녈 만난 많은 남자 중에\n",
        "내 친구만도 여러명이야\n",
        "말도 안돼 믿을 수 없어\n",
        "혹시 쌍둥이\n",
        "우연히 너를 보았지\n",
        "다른 남자품안에 너를\n",
        "한번도 볼 수 없었던\n",
        "너무 행복한 미소\n",
        "내 사랑은 무너져 버렸어\n",
        "그게 아냐 변명이 아니라\n",
        "그 남자는 나완 상관없어\n",
        "잠시 나 어지러웠어\n",
        "기댄 것 뿐이야\n",
        "날 오해하지 말아 줘\n",
        "나 역시 많은 여자들\n",
        "만났다가 헤어져도 봤지만\n",
        "한꺼번에 많은 여자를\n",
        "만난 적은 없었어\n",
        "니가 뭔데 날 아프게 하니\n",
        "너 때문에 상처돼 버린 내 사랑\n",
        "이제 다시는 너의 어떤 만남도\n",
        "나같은 사랑 없을걸\n",
        "난 두려워 나 역시 다시는\n",
        "이런 사랑 할수 없을까봐\n",
        "믿을 수 없겠지만은\n",
        "니가 첫사랑인데\n",
        "떠나버리면 어떡하라구\n",
        "사랑까지는 바라지도 않을께\n",
        "네 곁에 항상 있게만 해줘\n",
        "제발 제발\n",
        "\"\"\",\"\"\"\n",
        "마음 울적한 날엔 거리를 걸어보고\n",
        "향기로운 칵테일에 취해도보고\n",
        "한편의 시가 있는 전시회장도 가고\n",
        "밤새도록 그리움에 편질 쓰고파\n",
        "모차르트 피아노 협주곡 이십일번\n",
        "그 음악을 내 귓가에 속삭여주며\n",
        "아침 햇살 눈부심에 나를 깨워줄\n",
        "그런 연인이 내게 있으면\n",
        "나는 아직 순수함을 느끼고 싶어\n",
        "어느 작은 우체국 앞 계단에 앉아\n",
        "프리지아 꽃 향기를 내게 안겨줄\n",
        "그런 연인을 만나 봤으면\n",
        "마음 울적한 날엔 거리를 걸어보고\n",
        "향기로운 칵테일에 취해도보고\n",
        "한편의 시가 있는 전시회장도 가고\n",
        "밤새도록 그리움에 편질 쓰고파\n",
        "모차르트 피아노 협주곡 이십일번\n",
        "그 음악을 내 귓가에 속삭여 주며\n",
        "아침 햇살 눈부심에 나를 깨워줄\n",
        "그런 연인이 내게 있으면\n",
        "나는 아직 순수함을 느끼고 싶어\n",
        "어느 작은 우체국 앞 계단에 앉아\n",
        "프리지아 꽃향기를 내게 안겨줄\n",
        "그런 연인을 만나 봤으면\n",
        "마음 울적한 날엔 거리를 걸어보고\n",
        "향기로운 칵테일에 취해도보고\n",
        "한편의 시가 있는 전시회장도 가고\n",
        "밤새도록 그리움에 편질 쓰고파\n",
        "창밖에는 우울한 비가 내리고 있어\n",
        "내 마음도 그 비따라 우울해지네\n",
        "누가 내게 눈부신 사랑을 가져 줄까\n",
        "이 세상은 나로 인해 아름다운데\n",
        "마음 울적한 날엔 거리를 걸어보고\n",
        "향기로운 칵테일에 취해도보고\n",
        "한편의 시가 있는 전시회장도 가고\n",
        "밤새도록 그리움에 편질 쓰고파\n",
        "\"\"\",\"\"\"\n",
        "니가 없는 거리에는 내가 할 일이 없어서\n",
        "마냥 걷다 걷다 보면 추억을 가끔 마주치지\n",
        "떠오르는 너의 모습 내 살아나는 그리움 한 번에\n",
        "참 잊기 힘든 사람이란 걸 또 한 번 느껴지는 하루\n",
        "어디쯤에 머무는지 또 어떻게 살아가는지\n",
        "걷다 보면 누가 말해줄 것 같아\n",
        "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
        "그리운 날들 오늘 밤 나를 찾아온다\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
        "막다른 길 다다라서 낯익은 벽 기대 보면\n",
        "가로등 속 환히 비춰지는 고백하는 니가 보여\n",
        "떠오르는 그때 모습 내 살아나는 설레임 한 번에\n",
        "참 잊기 힘든 순간이란 걸 또 한 번 느껴지는 하루\n",
        "아직 나를 생각할지 또 그녀도 나를 찾을지\n",
        "걷다 보면 누가 말해줄 것 같아\n",
        "이 거리가 익숙했던 우리 발걸음이 나란했던\n",
        "그리운 날들 오늘 밤 나를 찾아온다\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만 가득해\n",
        "부풀은 내 가슴이 밤하늘에 외쳐본다\n",
        "이 거리는 널 기다린다고\n",
        "널 그리는 널 부르는 내 하루는\n",
        "애태워도 마주친 추억이 반가워\n",
        "날 부르는 목소리에 돌아보면\n",
        "텅 빈 거리 어느새 수많은 니 모습만\n",
        "가득해\n",
        "\"\"\",\"\"\"\n",
        "너와 나 둘이 정신없이 가는 곳\n",
        "정처 없이 가는 곳, 정해지지 않은 곳\n",
        "거기서 우리 (whoa-whoa) 서로를 재워주고 (whoa-whoa)\n",
        "서로를 깨워주고 (whoa-whoa) 서로를 채워주고 (whoa-whoa)\n",
        "Excuse me 잠시만 아직까진 우린 남\n",
        "하지만 조만간 중독성을 자랑하는 장난감\n",
        "지금 이 느낌적인 느낌이 통하는 느낌\n",
        "녹아버릴 아이스크림\n",
        "지금이 우리에게는 꿈이야\n",
        "너와 나 둘이서 추는 춤이야\n",
        "기분은 미친 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "하늘을 날아가는 기분이야\n",
        "죽어도 상관없는 지금이야\n",
        "심장은 터질 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "예술이야 (예술이야), 예술이야 (예술이야)\n",
        "예술이야 (예술이야), 이런 날이 올 줄이야\n",
        "예술이야 (예술이야), 예술이야 (예술이야)\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "너와 나 둘이 (whoa-whoa) 밤새 잔을 부딪혀 (whoa-whoa)\n",
        "밤새 뺨을 부비며 (whoa-whoa) 밤새도록 둘이서 (whoa-whoa)\n",
        "눈이 점점 풀린다\n",
        "니도 따라 풀린다\n",
        "끌린다, 너에 대한 수수께끼가 풀린다\n",
        "지금 이 춤에 너의 가빠진 숨에\n",
        "수줍음에 you know what I mean\n",
        "지금이 우리에게는 꿈이야\n",
        "너와 나 둘이서 추는 춤이야\n",
        "기분은 미친 듯이 예술이야\n",
        "Ooh-eh-oh, ooh-eh-oh, ooh-eh-oh\n",
        "하늘을 날아가는 기분이야\n",
        "죽어도 상관없는 지금이야\"\"\"]\n",
        "\n",
        "# # 모델과 토크나이저 로드\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "# # 입력 텍스트를 토큰화\n",
        "# inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# 예측 수행\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    logits = outputs.logits\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "# 결과 출력 및 시각화\n",
        "for i, text in enumerate(input_texts):\n",
        "    print(f\"Input: {text}\")\n",
        "    # print(f\"Prediction: {id2label[predictions[i].item()]} (Probability: {probabilities[i][predictions[i]].item():.4f})\")\n",
        "\n",
        "    top_probabilities, top_indices = torch.topk(probabilities[i], 10)\n",
        "    for j in range(10):\n",
        "        print(f\"Top {j+1} Prediction: {id2label[top_indices[j].item()]} (Probability: {top_probabilities[j].item():.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IFEm6aZQpFq"
      },
      "source": [
        "# 문제점 발견 -> 감정간 유사도를 conv로는 반열할 수 없을거 같음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rLdI--mQu0r"
      },
      "source": [
        "# 마지막단 MLP 하나 달아서 앞에거 다 freezing하고 마무리 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amjt7NjRQng4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP_HW2",
      "language": "python",
      "name": "nlp_hw2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
